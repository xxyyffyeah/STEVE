{
    "test_acc": [
        [
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1
        ],
        [
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1
        ],
        [
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1
        ],
        [
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            0,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1
        ],
        [
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            1,
            1,
            1,
            0,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            0,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            0,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1,
            1
        ]
    ],
    "prompt": [
        "Answer the following yes/no question. Think step by step and provide reasoning before answering. The last line of your response should be of the following format: 'Answer: True' or 'Answer: False'.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n- Use only the given quantities and definitions; do not invent scenarios or numbers or introduce irrelevant calculations.\n- Normalize wording to a numeric/boolean comparison:\n  - \u201cenough X for Y\u201d \u2192 test X \u2265 Y.\n  - \u201ccommas in a billion\u201d \u2192 3.\n  - \u201cWould it stick out?\u201d \u2192 compare object height to water depth; if both average and maximum depths are provided, use the maximum depth (hardest case).\n- Normalize units before comparing (convert all values to the same unit). Compute delta = A \u2212 B and note its sign.\n  - If delta > 0 and the question asks whether A meets/exceeds B (e.g., sticks out, at least/enough), map to True.\n  - If delta \u2264 0, map to False.\n  - Adjust mapping according to the question\u2019s polarity.\n- Polarity/negation guard: identify words like not, no, without, fewer than, at most/at least; restate the claim positively; ensure Yes maps to True and No maps to False.\n- Final self-check: used only provided facts; compared the correct pair (e.g., height vs maximum depth when applicable); units consistent; sign consistent with the question\u2019s polarity; exactly one Answer: token; output string matches the required format.\n\nThen emit only the single required line.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n- Use only the provided facts and the whitelisted micro-glossary below; do not invent scenarios, numbers, or irrelevant calculations.\n\n- Normalize wording to a numeric/boolean comparison where possible:\n  - \u201cenough X for Y\u201d \u2192 test X \u2265 Y.\n  - \u201cWould it stick out?\u201d \u2192 compare object height to water depth; if both average and maximum depths are provided, use the maximum depth (hardest case).\n  - \u201ccommas in a billion\u201d \u2192 3.\n  - Normalize units before comparing (convert all values to the same unit). Compute delta = A \u2212 B and note its sign.\n  - Mapping: if the question asks whether A meets/exceeds B (at least/enough/sticks out) and delta > 0 (or \u2265 0 as appropriate), map to True; otherwise map to False. Adjust for the question\u2019s polarity.\n\n- Polarity/negation guard and synonym normalization:\n  - Detect not, no, without, fewer than, at most/at least, same/different, similar/dissimilar, like/unlike.\n  - Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n  - Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar,\u201d \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n  - Restate the claim positively; ensure Yes \u2192 True and No \u2192 False when deciding the final output.\n\n- Categorical/semantic normalization (beyond numeric):\n  - For similarity/dissimilarity questions, reduce to a property-consistency check:\n    - Restate internally: \u201cAre X dissimilar to Y?\u201d \u2192 \u201cDoes X have a property that contradicts Y\u2019s defining property?\u201d If yes, output True; if properties align, output False.\n  - Property-contradiction heuristic: if X has property P and Y is defined by not-P (or vice versa), conclude dissimilar \u2192 True; if properties match, conclude similar \u2192 False.\n  - Normalize terms: treat \u201cneedles\u201d as a type of \u201cleaves\u201d for leaf-retention/shedding logic; normalize \u201ckeeps \u2026 all year\u201d \u2194 \u201cdoes not shed seasonally.\u201d\n\n- Quantifier and typicality handling:\n  - If the question refers to a generic or typical member of a group (e.g., \u201ca student,\u201d \u201cChristmas trees \u2026\u201d) and the facts use \u201cmost/usually/typically/generally,\u201d decide based on the majority case. Majority-truth is sufficient for True unless the question explicitly requires universality (\u201call/always/every\u201d).\n  - Do not flip to False merely because a statement is not universal if the question is about a typical member.\n\n- Temporal/age and threshold computations:\n  - If given a birth year and an event year, compute age_at_event = event_year \u2212 birth_year using only the provided years (no month/day speculation).\n  - Interpret \u201cbefore N\u201d as age < N (strict). For ranges like \u201cbefore 2 or 3,\u201d use the more inclusive/higher bound for majority statements (treat as \u201cbefore 3\u201d). If age equals one threshold but a higher alternative is offered, use the higher threshold.\n  - For probabilistic facts (\u201cmost\u201d), if the computed value is on/near the threshold, prefer the majority-consistent decision rather than demanding certainty.\n\n- Uncertainty resolution:\n  - If the glossary-based categorical mapping yields a clear direction, commit to that True/False; do not default to False solely due to absence of numeric quantities.\n\nWhitelisted micro-glossary (allowed definitions):\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers (needle retention = leaf retention).\n- pine trees are evergreen.\n\nUltra-compact internal exemplars (do not output):\n- Example A (dissimilarity): X = Christmas trees (usually pine \u2192 evergreen \u2192 keeps needles) vs Y = deciduous (sheds leaves). Properties contradict \u2192 dissimilar? yes \u2192 Answer: True.\n- Example B (memory/age): birth 1999, event 2001 \u2192 age_at_event = 2; \u201cmost adults do not remember before 2 or 3\u201d \u2192 majority cutoff < 3; \u201chave amnesia about event?\u201d at age 2 \u2192 within \u201cmost\u201d \u2192 True.\n\nFinal self-check (do not output):\n- Only used provided facts and the glossary; normalized units/terms correctly (including needles\u2194leaves, keep\u2194shed).\n- Converted language to the correct numeric/boolean or categorical comparison; applied polarity mapping (including amnesia/remember and similar/dissimilar).\n- Applied quantifier/typicality rule (generic subject + \u201cmost/usually\u201d \u2192 majority-case decision).\n- For age/event tasks: computed age_at_event correctly; applied \u201cbefore N\u201d as < N; used higher bound where applicable.\n- Tie-breaking near thresholds follows majority intent.\n- Output compliance: exactly one line; exactly one \u201cAnswer:\u201d; matches regex ^Answer:\\s*(True|False)\\s*$; correct casing; no trailing punctuation, no extra whitespace or lines.\n\nThen emit only the single required line.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n- Evidence use: Use only the provided facts and the whitelisted micro-glossary below; do not invent scenarios, numbers, or irrelevant calculations.\n\n- Normalize wording to a numeric/boolean comparison where possible:\n  - \u201cenough X for Y\u201d \u2192 test X \u2265 Y.\n  - \u201cWould it stick out?\u201d \u2192 compare object height to water depth; if both average and maximum depths are provided, use the maximum depth (hardest case).\n  - \u201ccommas in a billion\u201d \u2192 3.\n  - Normalize units before comparing (convert all values to the same unit). Compute delta = A \u2212 B and note its sign.\n  - Mapping: if the question asks whether A meets/exceeds B (at least/enough/sticks out) and delta > 0 (or \u2265 0 as appropriate), map to True; otherwise map to False. Adjust for the question\u2019s polarity.\n\n- Polarity/negation guard with mandatory restatement:\n  - Detect not, no, without, fewer than, at most/at least, same/different, similar/dissimilar, like/unlike.\n  - Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n  - Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar,\u201d \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n  - Restate the proposition internally without negation into a positive form aligned to the glossary (e.g., \u201cIs X not similar to Y?\u201d \u2192 \u201cX is dissimilar to Y;\u201d \u201cIs X valuable?\u201d with intrinsic facts \u2192 \u201cX has intrinsic value.\u201d). Ensure True corresponds to the positive assertion and False to its denial. Re-run polarity mapping after this restatement before finalizing.\n\n- Categorical/semantic normalization (beyond numeric):\n  - For similarity/dissimilarity questions, reduce to a property-consistency check:\n    - Internally: \u201cAre X dissimilar to Y?\u201d \u2192 \u201cDoes X have a property that contradicts Y\u2019s defining property?\u201d If yes, output True; if properties align, output False.\n  - Property-contradiction heuristic: if X has property P and Y is defined by not-P (or vice versa), conclude dissimilar \u2192 True; if properties match, conclude similar \u2192 False.\n  - Normalize terms: treat \u201cneedles\u201d as a type of \u201cleaves\u201d for leaf-retention/shedding logic; normalize \u201ckeeps \u2026 all year\u201d \u2194 \u201cdoes not shed seasonally.\u201d\n\n- Quantifier handling:\n  - Generic/typical subjects with \u201cmost/usually/typically/generally\u201d \u2192 decide based on the majority case. Majority-truth is sufficient for True unless the question explicitly requires universality (\u201call/always/every\u201d).\n  - Absolute claims (no quantifier): any provided fact that directly contradicts the proposition forces False, even if other facts suggest plausibility. Do not flip to False merely because a statement is not universal if the question is about a typical member.\n\n- Temporal/age and threshold computations:\n  - If given a birth year and an event year, compute age_at_event = event_year \u2212 birth_year using only the provided years (no month/day speculation).\n  - Interpret \u201cbefore N\u201d as age < N (strict). For ranges like \u201cbefore 2 or 3,\u201d use the more inclusive/higher bound for majority statements (treat as \u201cbefore 3\u201d). If age equals one threshold but a higher alternative is offered, use the higher threshold.\n  - For probabilistic facts (\u201cmost\u201d), if the computed value is on/near the threshold, prefer the majority-consistent decision rather than demanding certainty.\n\n- Conflict-resolution hierarchy (highest to lowest priority):\n  1) Direct definitional/property statements that match or negate the question\u2019s predicate (especially explicit negation).\n  2) Category implications from the whitelisted micro-glossary.\n  3) Indirect/numeric correlates or incidental facts.\n  Apply this hierarchy so that direct definitional denials outweigh tangential evidence (e.g., exchange rates).\n\n- Targeted semantic normalization for \u201cvalue\u201d:\n  - valuable/has value \u2192 interpret as has intrinsic value when the facts/glossary explicitly discuss intrinsic value.\n  - worth/price/exchange rate \u2192 exchange value; does not imply intrinsic value.\n  - fiat money \u2192 backed by government decree; has no intrinsic value.\n  - Direct-predicate alignment: if the question\u2019s key predicate (e.g., value) appears in the facts with explicit negation (e.g., \u201cno intrinsic value\u201d), treat that as overriding contradictory exchange-rate facts.\n\n- Ambiguity resolution:\n  - If a term has multiple readings, choose the reading explicitly defined by the provided facts/micro-glossary.\n  - If two readings remain and lead to conflicting conclusions, prefer the tighter/defined reading (e.g., intrinsic value over exchange rate) and decide accordingly.\n  - If ambiguity persists after these steps, prefer False to avoid over-claiming.\n\n- Bias mitigation against defaulting to True:\n  - Explicitly attempt to construct a counterexample from the provided facts that would falsify the proposition. If any direct counterfact exists (especially a definitional denial), set final_bool = False. This is a hard rule for absolute yes/no questions lacking quantifiers.\n\n- Uncertainty resolution:\n  - If the glossary-based categorical mapping yields a clear direction, commit to that True/False; do not default to False solely due to absence of numeric quantities unless guided by the ambiguity rule above.\n\nDeterministic finalization and emission (do not output any of these steps):\n- Compute internally a single boolean variable final_bool \u2208 {True, False}.\n- Perform a flip-check against the negation-free restatement of the proposition to ensure polarity is correct.\n- Pre-emission checklist for parser safety:\n  - Construct the output candidate exactly as \u201cAnswer: {final_bool}\u201d.\n  - Verify there is exactly one occurrence of \u201cAnswer:\u201d.\n  - Verify it matches the regex ^Answer:\\s*(True|False)$ (no trailing spaces, no extra characters or lines).\n  - If any check fails, rebuild the string from final_bool and revalidate.\n\nWhitelisted micro-glossary (allowed definitions):\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers (needle retention = leaf retention).\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed in facts) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n\nUltra-compact internal exemplars (do not output):\n- Example A (dissimilarity): X = Christmas trees (usually pine \u2192 evergreen \u2192 keeps needles) vs Y = deciduous (sheds leaves). Properties contradict \u2192 dissimilar? yes \u2192 Answer: True.\n- Example B (memory/age): birth 1999, event 2001 \u2192 age_at_event = 2; \u201cmost adults do not remember before 2 or 3\u201d \u2192 majority cutoff < 3; \u201chave amnesia about event?\u201d at age 2 \u2192 within \u201cmost\u201d \u2192 True.\n- Example C (value semantics): \u201cFiat money \u2192 no intrinsic value; Q: \u2018Is fiat money valuable?\u2019\u201d \u2192 map \u201cvaluable\u201d to intrinsic value per glossary \u2192 direct definitional denial \u2192 Answer: False, even if an exchange rate is provided.\n\nFinal self-check (do not output):\n- Only used provided facts and the micro-glossary; normalized units/terms correctly (including needles\u2194leaves, keep\u2194shed).\n- Converted language to the correct numeric/boolean or categorical comparison; applied polarity mapping (including amnesia/remember and similar/dissimilar) after negation-free restatement.\n- Applied the conflict-resolution hierarchy and the value-semantics rule where relevant.\n- Applied quantifier handling (majority vs absolute) correctly.\n- Tie-breaking near thresholds follows majority intent; ambiguity defaults handled per rules.\n- Output compliance: exactly one line; exactly one \u201cAnswer:\u201d; matches regex ^Answer:\\s*(True|False)$; correct casing; no trailing punctuation, no extra whitespace or lines.\n\nThen emit only the single required line.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n- Evidence use: Use only the provided facts and the whitelisted micro-glossary below; do not invent scenarios, numbers, bridges, or irrelevant calculations.\n\n- Normalize wording to a numeric/boolean comparison where possible:\n  - \u201cenough X for Y\u201d \u2192 test X \u2265 Y.\n  - \u201cWould it stick out?\u201d \u2192 compare object height to water depth; if both average and maximum depths are provided, use the maximum depth (hardest case).\n  - \u201ccommas in a billion\u201d \u2192 3.\n  - Normalize units before comparing (convert all values to the same unit). Compute delta = A \u2212 B and note its sign.\n  - Mapping: if the question asks whether A meets/exceeds B (at least/enough/sticks out) and delta > 0 (or \u2265 0 as appropriate), map to True; otherwise map to False. Adjust for the question\u2019s polarity.\n\n- Polarity/negation guard with mandatory restatement:\n  - Detect not, no, without, fewer than, at most/at least, same/different, similar/dissimilar, like/unlike.\n  - Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n  - Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar,\u201d \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n  - Restate the proposition internally without negation into a positive form aligned to the glossary (e.g., \u201cIs X not similar to Y?\u201d \u2192 \u201cX is dissimilar to Y;\u201d \u201cIs X valuable?\u201d with intrinsic facts \u2192 \u201cX has intrinsic value.\u201d). Ensure True corresponds to the positive assertion and False to its denial. Re-run polarity mapping after this restatement before finalizing.\n\n- Categorical/semantic normalization (beyond numeric):\n  - For similarity/dissimilarity questions, reduce to a property-consistency check:\n    - Internally: \u201cAre X dissimilar to Y?\u201d \u2192 \u201cDoes X have a property that contradicts Y\u2019s defining property?\u201d If yes, output True; if properties align, output False.\n  - Property-contradiction heuristic: if X has property P and Y is defined by not-P (or vice versa), conclude dissimilar \u2192 True; if properties match, conclude similar \u2192 False.\n  - Normalize terms: treat \u201cneedles\u201d as a type of \u201cleaves\u201d for leaf-retention/shedding logic; normalize \u201ckeeps \u2026 all year\u201d \u2194 \u201cdoes not shed seasonally.\u201d\n\n- Quantifier and modality handling:\n  - Generic/typical subjects with \u201cmost/usually/typically/generally\u201d \u2192 decide based on the majority case. Majority-truth is sufficient for True unless the question explicitly requires universality (\u201call/always/every\u201d).\n  - Interpret \u201cwould\u201d as a majority/typical-behavior claim within the subject\u2019s domain, not mere possibility. Absence of explicit positive evidence for the majority case counts against True.\n  - Absolute claims (no quantifier): any provided fact that directly contradicts the proposition forces False, even if other facts suggest plausibility. Do not flip to False merely because a statement is not universal if the question is about a typical member.\n\n- Temporal/age and threshold computations:\n  - If given a birth year and an event year, compute age_at_event = event_year \u2212 birth_year using only the provided years (no month/day speculation).\n  - Interpret \u201cbefore N\u201d as age < N (strict). For ranges like \u201cbefore 2 or 3,\u201d use the more inclusive/higher bound for majority statements (treat as \u201cbefore 3\u201d). If age equals one threshold but a higher alternative is offered, use the higher threshold.\n  - For probabilistic facts (\u201cmost\u201d), if the computed value is on/near the threshold, prefer the majority-consistent decision rather than demanding certainty.\n\n- Conflict-resolution hierarchy (highest to lowest priority):\n  1) Direct definitional/property statements that match or negate the question\u2019s predicate (especially explicit negation).\n  2) Category implications from the whitelisted micro-glossary.\n  3) Indirect/numeric correlates or incidental facts.\n  Apply this hierarchy so that direct definitional denials outweigh tangential evidence (e.g., exchange rates).\n\n- Targeted semantic normalization for \u201cvalue\u201d:\n  - valuable/has value \u2192 interpret as has intrinsic value when the facts/glossary explicitly discuss intrinsic value.\n  - worth/price/exchange rate \u2192 exchange value; does not imply intrinsic value.\n  - fiat money \u2192 backed by government decree; has no intrinsic value.\n  - Direct-predicate alignment: if the question\u2019s key predicate (e.g., value) appears in the facts with explicit negation (e.g., \u201cno intrinsic value\u201d), treat that as overriding contradictory exchange-rate facts.\n\n- Role\u2192Topic entailment gate (hard, mandatory; do not output):\n  - Trigger: Questions of the form \u201cWould/Does/Do/Is [a role/profession X] [teach/do/cover Y]?\u201d or \u201cWould an X professor teach Y?\u201d\n  - Normalize to a domain-membership query: \u201cIs Y within X\u2019s domain?\u201d\n  - Require an explicit, whitelisted chain using only provided facts/glossary:\n    - Professor-of(D1) \u2192 primarily teaches D1-domain (majority norm), AND\n    - Y \u2208 D1-domain (either directly or via a short chain \u2264 2 hops of provided facts/glossary).\n  - Bridge-required rule: Cross-domain teaching (X-domain \u2260 Y-domain) needs an explicit bridging fact linking D1 to D2 or Y to D1; otherwise, unsupported.\n  - Domain-contrast as negative evidence: If facts tie Y to domain D2 and X to a different domain D1 with no D1\u2194D2 bridge, treat this mismatch as evidence against the claim.\n  - Support requirement for True: Do not emit True unless the above chain exists. If the chain cannot be built, set final_bool = False, even if the claim seems plausible in the real world.\n  - Modal discipline: Treat \u201cwould\u201d as majority behavior; without the chain, majority support is absent \u2192 False.\n\n- Ambiguity resolution:\n  - If a term has multiple readings, choose the reading explicitly defined by the provided facts/micro-glossary.\n  - If two readings remain and lead to conflicting conclusions, prefer the tighter/defined reading (e.g., intrinsic value over exchange rate) and decide accordingly.\n  - If ambiguity persists after these steps, prefer False to avoid over-claiming.\n\n- Bias mitigation against defaulting to True:\n  - Explicitly attempt to construct a counterexample from the provided facts that would falsify the proposition. If any direct counterfact exists (especially a definitional denial or domain mismatch under the Role\u2192Topic gate), set final_bool = False. This is a hard rule for absolute/\u201cwould\u201d yes/no questions lacking explicit support.\n\n- Uncertainty resolution:\n  - If the glossary-based categorical mapping yields a clear direction, commit to that True/False; do not default to False solely due to absence of numeric quantities unless guided by the ambiguity rule above. For Role\u2192Topic, the entailment gate must be satisfied for True.\n\nDeterministic finalization and emission (do not output any of these steps):\n- Compute internally a single boolean variable final_bool \u2208 {True, False}.\n- Perform a flip-check against the negation-free restatement of the proposition to ensure polarity is correct.\n- Entailment-gate check (if decision is True): Verify the Role\u2192Topic entailment gate was satisfied for any role\u2192activity/topic claim. If not satisfied, override final_bool = False.\n- Pre-emission checklist for parser safety:\n  - Construct the output candidate exactly as \u201cAnswer: {final_bool}\u201d.\n  - Verify there is exactly one occurrence of \u201cAnswer:\u201d.\n  - Verify it matches the regex ^Answer:\\s*(True|False)$ (no trailing spaces, no extra characters or lines).\n  - If any check fails, rebuild the string from final_bool and revalidate.\n\nWhitelisted micro-glossary (allowed definitions):\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers (needle retention = leaf retention).\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed in facts) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- professor of X primarily teaches X (X-domain) as the majority norm.\n\nUltra-compact internal exemplars (do not output):\n- Example A (dissimilarity): X = Christmas trees (usually pine \u2192 evergreen \u2192 keeps needles) vs Y = deciduous (sheds leaves). Properties contradict \u2192 dissimilar? yes \u2192 Answer: True.\n- Example B (memory/age): birth 1999, event 2001 \u2192 age_at_event = 2; \u201cmost adults do not remember before 2 or 3\u201d \u2192 majority cutoff < 3; \u201chave amnesia about event?\u201d at age 2 \u2192 within \u201cmost\u201d \u2192 True.\n- Example C (value semantics): \u201cFiat money \u2192 no intrinsic value; Q: \u2018Is fiat money valuable?\u2019\u201d \u2192 map \u201cvaluable\u201d to intrinsic value per glossary \u2192 direct definitional denial \u2192 Answer: False.\n- Example D (role\u2192topic gate): \u201cWould an ethics professor teach (about) C\u00e9zanne?\u201d Normalize to \u201cIs C\u00e9zanne/art in ethics domain?\u201d Facts: C\u00e9zanne \u2208 art; aesthetics \u2192 arts; ethics \u2192 moral principles; no bridge ethics\u2194arts; domain mismatch \u2192 gate fails \u2192 Answer: False.\n\nFinal self-check (do not output):\n- Only used provided facts and the micro-glossary; normalized units/terms correctly (including needles\u2194leaves, keep\u2194shed).\n- Converted language to the correct numeric/boolean or categorical comparison; applied polarity mapping (including amnesia/remember and similar/dissimilar) after negation-free restatement.\n- Applied the conflict-resolution hierarchy and the value-semantics rule where relevant.\n- For role\u2192topic questions, enforced the entailment gate and bridge-required rule; treated \u201cwould\u201d as majority/typical behavior.\n- Applied quantifier handling (majority vs absolute) correctly.\n- Tie-breaking near thresholds follows majority intent; ambiguity defaults handled per rules.\n- Output compliance: exactly one line; exactly one \u201cAnswer:\u201d; matches regex ^Answer:\\s*(True|False)$; correct casing; no trailing punctuation, no extra whitespace or lines.\n\nThen emit only the single required line.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n- Evidence use: Use only the provided facts and the whitelisted micro-glossary below; do not invent scenarios, numbers, bridges, or irrelevant calculations.\n\n- Normalize wording to a numeric/boolean comparison where possible:\n  - \u201cenough X for Y\u201d \u2192 test X \u2265 Y.\n  - \u201cWould it stick out?\u201d \u2192 compare object height to water depth; if both average and maximum depths are provided, use the maximum depth (hardest case).\n  - \u201ccommas in a billion\u201d \u2192 3.\n  - Normalize units before comparing (convert all values to the same unit). Compute delta = A \u2212 B and note its sign.\n  - Mapping: if the question asks whether A meets/exceeds B (at least/enough/sticks out) and delta > 0 (or \u2265 0 as appropriate), map to True; otherwise map to False. Adjust for the question\u2019s polarity.\n\n- Polarity/negation guard with mandatory restatement:\n  - Detect not, no, without, fewer than, at most/at least, same/different, similar/dissimilar, like/unlike.\n  - Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n  - Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar,\u201d \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n  - Restate the proposition internally without negation into a positive form aligned to the glossary (e.g., \u201cIs X not similar to Y?\u201d \u2192 \u201cX is dissimilar to Y;\u201d \u201cIs X valuable?\u201d with intrinsic facts \u2192 \u201cX has intrinsic value.\u201d). Ensure True corresponds to the positive assertion and False to its denial. Re-run polarity mapping after this restatement before finalizing.\n\n- Categorical/semantic normalization (beyond numeric):\n  - For similarity/dissimilarity questions, reduce to a property-consistency check:\n    - Internally: \u201cAre X dissimilar to Y?\u201d \u2192 \u201cDoes X have a property that contradicts Y\u2019s defining property?\u201d If yes, output True; if properties align, output False.\n  - Property-contradiction heuristic: if X has property P and Y is defined by not-P (or vice versa), conclude dissimilar \u2192 True; if properties match, conclude similar \u2192 False.\n  - Normalize terms: treat \u201cneedles\u201d as a type of \u201cleaves\u201d for leaf-retention/shedding logic; normalize \u201ckeeps \u2026 all year\u201d \u2194 \u201cdoes not shed seasonally.\u201d\n\n- Quantifier and modality handling:\n  - Generic/typical subjects with \u201cmost/usually/typically/generally\u201d \u2192 decide based on the majority case. Majority-truth is sufficient for True unless the question explicitly requires universality (\u201call/always/every\u201d).\n  - Interpret \u201cwould\u201d as a majority/typical-behavior claim within the subject\u2019s domain, not mere possibility. Absence of explicit positive evidence for the majority case counts against True.\n  - Absolute claims (no quantifier): any provided fact that directly contradicts the proposition forces False, even if other facts suggest plausibility. Do not flip to False merely because a statement is not universal if the question is about a typical member.\n\n- Temporal/age and threshold computations:\n  - If given a birth year and an event year, compute age_at_event = event_year \u2212 birth_year using only the provided years (no month/day speculation).\n  - Interpret \u201cbefore N\u201d as age < N (strict). For ranges like \u201cbefore 2 or 3,\u201d use the more inclusive/higher bound for majority statements (treat as \u201cbefore 3\u201d). If age equals one threshold but a higher alternative is offered, use the higher threshold.\n  - For probabilistic facts (\u201cmost\u201d), if the computed value is on/near the threshold, prefer the majority-consistent decision rather than demanding certainty.\n\n- Conflict-resolution hierarchy (highest to lowest priority):\n  1) Direct definitional/property statements that match or negate the question\u2019s predicate (especially explicit negation).\n  2) Category implications from the whitelisted micro-glossary.\n  3) Indirect/numeric correlates or incidental facts.\n  Apply this hierarchy so that direct definitional denials outweigh tangential evidence (e.g., exchange rates).\n\n- Targeted semantic normalization for \u201cvalue\u201d:\n  - valuable/has value \u2192 interpret as has intrinsic value when the facts/glossary explicitly discuss intrinsic value.\n  - worth/price/exchange rate \u2192 exchange value; does not imply intrinsic value.\n  - fiat money \u2192 backed by government decree; has no intrinsic value.\n  - Direct-predicate alignment: if the question\u2019s key predicate (e.g., value) appears in the facts with explicit negation (e.g., \u201cno intrinsic value\u201d), treat that as overriding contradictory exchange-rate facts.\n\n- Role\u2192Topic entailment gate (hard, mandatory; do not output):\n  - Trigger: Questions of the form \u201cWould/Does/Do/Is [a role/profession X] [teach/do/cover Y]?\u201d or \u201cWould an X professor teach Y?\u201d\n  - Normalize to a domain-membership query: \u201cIs Y within X\u2019s domain?\u201d\n  - Require an explicit, whitelisted chain using only provided facts/glossary:\n    - Professor-of(D1) \u2192 primarily teaches D1-domain (majority norm), AND\n    - Y \u2208 D1-domain (either directly or via a short chain \u2264 2 hops of provided facts/glossary).\n  - Bridge-required rule: Cross-domain teaching (X-domain \u2260 Y-domain) needs an explicit bridging fact linking D1 to D2 or Y to D1; otherwise, unsupported.\n  - Domain-contrast as negative evidence: If facts tie Y to domain D2 and X to a different domain D1 with no D1\u2194D2 bridge, treat this mismatch as evidence against the claim.\n  - Support requirement for True: Do not emit True unless the above chain exists. If the chain cannot be built, set final_bool = False, even if the claim seems plausible in the real world.\n  - Modal discipline: Treat \u201cwould\u201d as majority behavior; without the chain, majority support is absent \u2192 False.\n\n- Ambiguity resolution:\n  - If a term has multiple readings, choose the reading explicitly defined by the provided facts/micro-glossary.\n  - If two readings remain and lead to conflicting conclusions, prefer the tighter/defined reading (e.g., intrinsic value over exchange rate) and decide accordingly.\n  - If ambiguity persists after these steps, prefer False to avoid over-claiming.\n\n- Bias mitigation against defaulting to True:\n  - Explicitly attempt to construct a counterexample from the provided facts that would falsify the proposition. If any direct counterfact exists (especially a definitional denial or domain mismatch under the Role\u2192Topic gate), set final_bool = False. This is a hard rule for absolute/\u201cwould\u201d yes/no questions lacking explicit support.\n\n- Uncertainty resolution:\n  - If the glossary-based categorical mapping yields a clear direction, commit to that True/False; do not default to False solely due to absence of numeric quantities unless guided by the ambiguity rule above. For Role\u2192Topic, the entailment gate must be satisfied for True.\n\nDeterministic finalization and emission (do not output any of these steps):\n- Compute internally a single boolean variable final_bool \u2208 {True, False}.\n- Perform a flip-check against the negation-free restatement of the proposition to ensure polarity is correct.\n- Entailment-gate check (if decision is True): Verify the Role\u2192Topic entailment gate was satisfied for any role\u2192activity/topic claim. If not satisfied, override final_bool = False.\n- Pre-emission checklist for parser safety:\n  - Construct the output candidate exactly as \u201cAnswer: {final_bool}\u201d.\n  - Verify there is exactly one occurrence of \u201cAnswer:\u201d.\n  - Verify it matches the regex ^Answer:\\s*(True|False)$ (no trailing spaces, no extra characters or lines).\n  - If any check fails, rebuild the string from final_bool and revalidate.\n\nWhitelisted micro-glossary (allowed definitions):\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers (needle retention = leaf retention).\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed in facts) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- professor of X primarily teaches X (X-domain) as the majority norm.\n\nUltra-compact internal exemplars (do not output):\n- Example A (dissimilarity): X = Christmas trees (usually pine \u2192 evergreen \u2192 keeps needles) vs Y = deciduous (sheds leaves). Properties contradict \u2192 dissimilar? yes \u2192 Answer: True.\n- Example B (memory/age): birth 1999, event 2001 \u2192 age_at_event = 2; \u201cmost adults do not remember before 2 or 3\u201d \u2192 majority cutoff < 3; \u201chave amnesia about event?\u201d at age 2 \u2192 within \u201cmost\u201d \u2192 True.\n- Example C (value semantics): \u201cFiat money \u2192 no intrinsic value; Q: \u2018Is fiat money valuable?\u2019\u201d \u2192 map \u201cvaluable\u201d to intrinsic value per glossary \u2192 direct definitional denial \u2192 Answer: False.\n- Example D (role\u2192topic gate): \u201cWould an ethics professor teach (about) C\u00e9zanne?\u201d Normalize to \u201cIs C\u00e9zanne/art in ethics domain?\u201d Facts: C\u00e9zanne \u2208 art; aesthetics \u2192 arts; ethics \u2192 moral principles; no bridge ethics\u2194arts; domain mismatch \u2192 gate fails \u2192 Answer: False.\n\nFinal self-check (do not output):\n- Only used provided facts and the micro-glossary; normalized units/terms correctly (including needles\u2194leaves, keep\u2194shed).\n- Converted language to the correct numeric/boolean or categorical comparison; applied polarity mapping (including amnesia/remember and similar/dissimilar) after negation-free restatement.\n- Applied the conflict-resolution hierarchy and the value-semantics rule where relevant.\n- For role\u2192topic questions, enforced the entailment gate and bridge-required rule; treated \u201cwould\u201d as majority/typical behavior.\n- Applied quantifier handling (majority vs absolute) correctly.\n- Tie-breaking near thresholds follows majority intent; ambiguity defaults handled per rules.\n- Output compliance: exactly one line; exactly one \u201cAnswer:\u201d; matches regex ^Answer:\\s*(True|False)$; correct casing; no trailing punctuation, no extra whitespace or lines.\n\nThen emit only the single required line.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n- Evidence use: Use only the provided facts and the whitelisted micro-glossary below; do not invent scenarios, numbers, bridges, or irrelevant calculations.\n\n- Numeric/boolean normalization (make this operational and stepwise):\n  - Cross-category permission: If both sides can be reduced to plain counts/integers, compare the numbers even if the nouns differ (e.g., peas vs commas). Category/unit mismatch alone is not a reason to reject the comparison.\n  - Enough/at least pattern (mandatory steps):\n    1) Extract numeric X from the subject. If X is a range \u201cA or B,\u201d treat bounds explicitly (see Range handling below).\n    2) Resolve the requirement Y to a numeric threshold via provided facts/glossary (e.g., \u201ccommas in/for/of a billion\u201d \u2192 3).\n    3) Compute delta = X \u2212 Y.\n    4) For \u201cenough/at least\u201d claims, test X \u2265 Y. Map True if delta \u2265 0; otherwise False. Re-apply polarity if the question is negated.\n  - Fall-short/fewer-than pattern: \u201cfall short of/less than/fewer than\u201d \u2192 test X < Y; map accordingly.\n  - \u201cWould it stick out?\u201d \u2192 compare object height to water depth; if both average and maximum depths are provided, use the maximum depth (hardest case).\n  - Normalize units before comparing (convert to same unit), then compute delta and note its sign.\n  - Commas-in-billion constant and paraphrase normalization: Map each of the following deterministically to 3: \u201ccommas in a billion,\u201d \u201ccommas for a billion,\u201d \u201ccommas of a billion,\u201d \u201chow many commas does a billion have,\u201d and close paraphrases explicitly referring to commas with the number one billion.\n\n- Range handling for X (\u201cA or B\u201d or similar):\n  - For \u201cenough/at least\u201d comparisons:\n    - If both bounds \u2265 threshold \u2192 True.\n    - If both bounds < threshold \u2192 False.\n    - If one bound \u2265 and the other < threshold \u2192 use the typical/majority guidance if indicated; absent such, treat as mixed and follow the majority/typical intent (e.g., \u201caverage 6 or 7\u201d \u2192 consider the lower bound for conservative sufficiency checks).\n  - For \u201cfewer than/less than/fall short of\u201d comparisons:\n    - If both bounds < threshold \u2192 True.\n    - If both bounds \u2265 threshold \u2192 False.\n    - If mixed \u2192 follow majority/typical intent; absent such, treat the lower bound as representative for conservative \u201cfewer than\u201d claims.\n\n- Polarity/negation guard with mandatory restatement:\n  - Detect not, no, without, fewer than, fall short of, at most/at least, same/different, similar/dissimilar, like/unlike.\n  - Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n  - Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar,\u201d \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n  - Mandatory numeric restatement for sufficiency queries regardless of noun mismatch: e.g., \u201cIs average peas enough commas for a billion?\u201d \u2192 internally restate as \u201cIs average_peas \u2265 commas_in_billion?\u201d Then decide strictly from the inequality.\n  - Restate other negated propositions into a positive form aligned to the glossary. Ensure True corresponds to the positive assertion and False to its denial. Re-run polarity mapping after restatement.\n\n- Categorical/semantic normalization (beyond numeric):\n  - For similarity/dissimilarity questions, reduce to a property-consistency check:\n    - Internally: \u201cAre X dissimilar to Y?\u201d \u2192 \u201cDoes X have a property that contradicts Y\u2019s defining property?\u201d If yes \u2192 True; if properties align \u2192 False.\n  - Property-contradiction heuristic: if X has property P and Y is defined by not-P (or vice versa), conclude dissimilar \u2192 True; if properties match, conclude similar \u2192 False.\n  - Normalize terms: treat \u201cneedles\u201d as a type of \u201cleaves\u201d for leaf-retention/shedding logic; normalize \u201ckeeps \u2026 all year\u201d \u2194 \u201cdoes not shed seasonally.\u201d\n\n- Quantifier and modality handling:\n  - Generic/typical subjects with \u201cmost/usually/typically/generally\u201d \u2192 decide based on the majority case. Majority-truth is sufficient for True unless the question explicitly requires universality (\u201call/always/every\u201d).\n  - Interpret \u201cwould\u201d as a majority/typical-behavior claim within the subject\u2019s domain, not mere possibility. Absence of explicit positive evidence for the majority case counts against True.\n  - Absolute claims (no quantifier): any provided fact that directly contradicts the proposition forces False, even if other facts suggest plausibility. Do not flip to False merely because a statement is not universal if the question is about a typical member.\n\n- Temporal/age and threshold computations:\n  - If given a birth year and an event year, compute age_at_event = event_year \u2212 birth_year using only the provided years (no month/day speculation).\n  - Interpret \u201cbefore N\u201d as age < N (strict). For ranges like \u201cbefore 2 or 3,\u201d use the more inclusive/higher bound for majority statements (treat as \u201cbefore 3\u201d). If age equals one threshold but a higher alternative is offered, use the higher threshold.\n  - For probabilistic facts (\u201cmost\u201d), if the computed value is on/near the threshold, prefer the majority-consistent decision rather than demanding certainty.\n\n- Conflict-resolution hierarchy (highest to lowest priority):\n  1) Direct definitional/property statements that match or negate the question\u2019s predicate (especially explicit negation).\n  2) Category implications from the whitelisted micro-glossary.\n  3) Indirect/numeric correlates or incidental facts.\n  - Priority note: The \u201ccommas in/for/of a billion \u2192 3\u201d mapping is a direct definitional constant; apply it decisively even if nouns differ.\n\n- Targeted semantic normalization for \u201cvalue\u201d:\n  - valuable/has value \u2192 interpret as has intrinsic value when the facts/glossary explicitly discuss intrinsic value.\n  - worth/price/exchange rate \u2192 exchange value; does not imply intrinsic value.\n  - fiat money \u2192 backed by government decree; has no intrinsic value.\n  - Direct-predicate alignment: if the question\u2019s key predicate (e.g., value) appears in the facts with explicit negation (e.g., \u201cno intrinsic value\u201d), treat that as overriding contradictory exchange-rate facts.\n\n- Role\u2192Topic entailment gate (hard, mandatory; do not output):\n  - Trigger: Only apply to questions of the form \u201cWould/Does/Do/Is [a role/profession X] [teach/do/cover Y]?\u201d or \u201cWould an X professor teach Y?\u201d\n  - Normalize to a domain-membership query: \u201cIs Y within X\u2019s domain?\u201d\n  - Require an explicit, whitelisted chain using only provided facts/glossary:\n    - Professor-of(D1) \u2192 primarily teaches D1-domain (majority norm), AND\n    - Y \u2208 D1-domain (either directly or via a short chain \u2264 2 hops of provided facts/glossary).\n  - Bridge-required rule: Cross-domain teaching (X-domain \u2260 Y-domain) needs an explicit bridging fact linking D1 to D2 or Y to D1; otherwise, unsupported.\n  - Domain-contrast as negative evidence: If facts tie Y to domain D2 and X to a different domain D1 with no D1\u2194D2 bridge, treat this mismatch as evidence against the claim.\n  - Support requirement for True: Do not emit True unless the above chain exists. If the chain cannot be built, set final_bool = False.\n  - Do not apply this gate to pure numeric/comparison puzzles.\n\n- Ambiguity resolution:\n  - If a term has multiple readings, choose the reading explicitly defined by the provided facts/micro-glossary.\n  - If two readings remain and lead to conflicting conclusions, prefer the tighter/defined reading (e.g., intrinsic value over exchange rate) and decide accordingly.\n  - Once both sides have been deterministically mapped to numbers and compared via the rules above, do not treat cross-noun semantics as ambiguity. Only an explicit factual contradiction can overturn the numeric result.\n  - If ambiguity persists after these steps, prefer False to avoid over-claiming.\n\n- Bias mitigation against defaulting to True:\n  - Attempt to construct a counterexample only from the provided facts. Category/unit mismatch alone is not a counterexample if numeric reduction has been sanctioned.\n  - If any direct counterfact exists (especially a definitional denial or a Role\u2192Topic domain mismatch), set final_bool = False for absolute/\u201cwould\u201d claims lacking explicit support.\n\n- Uncertainty resolution:\n  - If the glossary-based categorical or numeric mapping yields a clear direction, commit to that True/False; do not default to False solely due to absence of extra numeric detail. For Role\u2192Topic, the entailment gate must be satisfied for True.\n\nDeterministic finalization and emission (do not output any of these steps):\n- Compute internally a single boolean variable final_bool \u2208 {True, False}.\n- Perform a flip-check against the negation-free restatement of the proposition to ensure polarity is correct.\n- Role\u2192Topic entailment-gate check (if decision is True): Verify the gate was satisfied for any role\u2192activity/topic claim. If not satisfied, override final_bool = False.\n- Numeric True-protection: If, under the \u201cenough/at least\u201d rule, numeric normalization yields X \u2265 Y and there is no direct counterfact, lock final_bool = True.\n- Pre-emission checklist for parser safety:\n  - Construct the output candidate exactly as \u201cAnswer: {final_bool}\u201d.\n  - Verify there is exactly one occurrence of \u201cAnswer:\u201d.\n  - Validate against both regexes: ^Answer:\\s*(True|False)$ and ^Answer:\\s*(True|False)\\s*$. If either fails, rebuild the string from final_bool and revalidate.\n  - Defensively ensure there are no invisible trailing spaces or newline characters after the final token.\n- Emit only the single required line.\n\nWhitelisted micro-glossary (allowed definitions):\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers (needle retention = leaf retention).\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed in facts) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- professor of X primarily teaches X (X-domain) as the majority norm.\n- commas in/for/of a billion = 3; \u201chow many commas does a billion have\u201d = 3.\n\nUltra-compact internal exemplars (do not output):\n- Example A (dissimilarity): X = Christmas trees (usually pine \u2192 evergreen \u2192 keeps needles) vs Y = deciduous (sheds leaves). Properties contradict \u2192 dissimilar? yes \u2192 Answer: True.\n- Example B (memory/age): birth 1999, event 2001 \u2192 age_at_event = 2; \u201cmost adults do not remember before 2 or 3\u201d \u2192 majority cutoff < 3; \u201chave amnesia about event?\u201d at age 2 \u2192 within \u201cmost\u201d \u2192 True.\n- Example C (value semantics): \u201cFiat money \u2192 no intrinsic value; Q: \u2018Is fiat money valuable?\u2019\u201d \u2192 map \u201cvaluable\u201d to intrinsic value per glossary \u2192 direct definitional denial \u2192 Answer: False.\n- Example D (role\u2192topic gate): \u201cWould an ethics professor teach (about) C\u00e9zanne?\u201d Normalize to \u201cIs C\u00e9zanne/art in ethics domain?\u201d Facts: C\u00e9zanne \u2208 art; aesthetics \u2192 arts; ethics \u2192 moral principles; no bridge ethics\u2194arts; domain mismatch \u2192 gate fails \u2192 Answer: False.\n- Example E (cross-category numeric sufficiency): X = average peas per pod = \u201c6 or 7\u201d; Y = commas in/for/of a billion = 3; test X \u2265 Y under \u201cenough\u201d \u2192 True.\n\nFinal self-check (do not output):\n- Only used provided facts and the micro-glossary; normalized units/terms correctly (including needles\u2194leaves, keep\u2194shed, commas-in-billion constant).\n- Converted language to the correct numeric/boolean or categorical comparison; applied polarity mapping (including amnesia/remember and similar/dissimilar) after negation-free restatement.\n- Applied the conflict-resolution hierarchy and the value-semantics rule where relevant.\n- For role\u2192topic questions, enforced the entailment gate and bridge-required rule; treated \u201cwould\u201d as majority/typical behavior.\n- Applied quantifier handling (majority vs absolute) correctly; handled ranges per rules.\n- Tie-breaking near thresholds follows majority intent; ambiguity defaults handled per rules and never override a resolved numeric inequality.\n- Output compliance: exactly one line; exactly one \u201cAnswer:\u201d; matches ^Answer:\\s*(True|False)$; no trailing punctuation, no extra whitespace or lines. Then emit only the single required line.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, or outside knowledge.\n\nDecision algorithm (internal; do not output):\n1) Normalize the claim\n- Detect polarity: not, no, without, fewer/less than, fall short of, at most/at least, same/different, similar/dissimilar, like/unlike, would.\n- Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n- Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar\u201d; \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n- Value terms: valuable/has value \u2192 intrinsic value when facts mention intrinsic value; worth/price/exchange rate \u2192 exchange value (not intrinsic).\n- Political/structure normalization:\n  - monarchy \u2192 citizens do not elect their rulers. For \u201cDid [group] elect rulers in a monarchy?\u201d treat as False unless the facts explicitly grant that group the power to elect rulers. Absence of such permission counts against True.\n  - Superset prohibition monotonicity: If facts deny an action to a broad group (e.g., \u201ccitizens cannot A\u201d), treat the same action as denied for any subgroup unless a contrary exception is explicitly provided.\n\n2) Numeric/boolean handling\n- Normalize units before comparing.\n- Enough/at least: extract X, map requirement Y via facts/glossary, compute X \u2212 Y; test X \u2265 Y.\n- Fewer/less than/fall short of: test X < Y.\n- Ranges \u201cA or B\u201d:\n  - For enough/at least: both \u2265 \u2192 True; both < \u2192 False; mixed \u2192 use majority/typical guidance if given; otherwise use the lower bound conservatively.\n  - For fewer/less than/fall short of: both < \u2192 True; both \u2265 \u2192 False; mixed \u2192 use lower bound conservatively.\n- \u201cWould it stick out?\u201d \u2192 compare object height vs water depth; if both average and maximum depths are given, use maximum depth.\n- Temporal/age: if given birth year and event year, age = event_year \u2212 birth_year (no month/day speculation). \u201cBefore N\u201d \u2192 age < N (strict).\n\n3) Quantifiers and modality\n- Most/usually/typically/generally \u2192 decide by majority case (True if majority supports).\n- \u201cWould\u201d \u2192 typical/majority behavior within the stated domain; mere possibility is insufficient.\n- Absolute claims (no quantifier): any direct contradictory fact forces False.\n\n4) Conflict resolution (priority highest\u2192lowest)\n- Direct definitional/property statements that match/negate the predicate.\n- Category implications from the micro-glossary.\n- Indirect/numeric correlates or incidental facts.\n- Ambiguity that remains after these steps defaults to False (avoid over-claiming).\n\n5) Role\u2192Topic entailment gate (only for \u201cWould/Does/Do/Is [role/profession X] [teach/do/cover Y]?\u201d)\n- Professor-of(D1) \u2192 primarily teaches D1 (majority norm), and Y must be within D1 (directly or via a provided \u22642-hop bridge).\n- Cross-domain claims need an explicit provided bridge; without it, set False.\n- Do not apply this gate to pure numeric/comparison puzzles.\n\nDeterministic finalization (internal; do not output):\n- Compute final_bool \u2208 {True, False}.\n- Flip-check against the negation-free restatement to ensure polarity is correct.\n- Numeric True-protection: If X \u2265 Y under the \u201cenough/at least\u201d rule and no direct counterfact exists, lock True.\n- Pre-emit format check:\n  - Build exactly \u201cAnswer: {final_bool}\u201d.\n  - Ensure exactly one \u201cAnswer:\u201d and match ^Answer:\\s*(True|False)$.\n  - Ensure no trailing spaces or newlines.\n- Emit only the single required line.\n\nWhitelisted micro-glossary:\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers.\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- professor of X primarily teaches X (X-domain) as the majority norm.\n- commas in/for/of a billion = 3; \u201chow many commas does a billion have\u201d = 3.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles, disciplines, or outside knowledge.\n\nDecision algorithm (internal; do not output):\n1) Normalize the claim\n- Detect polarity: not, no, without, fewer/less than, fall short of, at most/at least, same/different, similar/dissimilar, like/unlike, would.\n- Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n- Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar\u201d; \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n- Value terms: valuable/has value \u2192 intrinsic value when facts mention intrinsic value; worth/price/exchange rate \u2192 exchange value (not intrinsic).\n- Political/structure normalization:\n  - monarchy \u2192 citizens do not elect their rulers. For \u201cDid [group] elect rulers in a monarchy?\u201d treat as False unless the facts explicitly grant that group the power to elect rulers. Absence of such permission counts against True.\n  - Superset prohibition monotonicity: If facts deny an action to a broad group (e.g., \u201ccitizens cannot A\u201d), treat the same action as denied for any subgroup unless a contrary exception is explicitly provided.\n\n2) Numeric/boolean handling\n- Normalize units before comparing.\n- Enough/at least: extract X, map requirement Y via facts/glossary, compute X \u2212 Y; test X \u2265 Y.\n- Fewer/less than/fall short of: test X < Y.\n- Ranges \u201cA or B\u201d:\n  - For enough/at least: both \u2265 \u2192 True; both < \u2192 False; mixed \u2192 use majority/typical guidance if given; otherwise use the lower bound conservatively.\n  - For fewer/less than/fall short of: both < \u2192 True; both \u2265 \u2192 False; mixed \u2192 use lower bound conservatively.\n- Temporal/age:\n  - If given birth year and event year, age = event_year \u2212 birth_year (no month/day speculation).\n  - \u201cBefore N\u201d \u2192 age < N (strict).\n  - Childhood amnesia rule: If a fact states \u201cmost [people] do not remember before N or M years,\u201d treat the majority cutoff as max(N, M). If age at event < cutoff, then typical/majority \u201cwould not remember\u201d (i.e., \u201chave amnesia about\u201d is True), absent a direct counterfact.\n\n3) Quantifiers and modality\n- Most/usually/typically/generally \u2192 decide by the majority case (True if majority supports).\n- \u201cWould\u201d \u2192 typical/majority behavior within the stated domain; mere possibility is insufficient.\n- Absolute claims (no quantifier): any direct contradictory fact forces False.\n\n4) Conflict resolution (priority highest\u2192lowest)\n- Direct definitional/property statements that match/negate the predicate.\n- Category implications from the micro-glossary.\n- Indirect/numeric correlates or incidental facts.\n- Ambiguity that remains after these steps defaults to False (avoid over-claiming).\n\n5) Role\u2192Topic entailment gate (only for \u201cWould/Does/Do/Is [role/profession X] [teach/do/cover Y]?\u201d)\n- Professor-of(D1) \u2192 primarily teaches D1 (majority norm), and Y must be within D1 (directly or via a provided \u22642-hop bridge).\n- Ethics and aesthetics are distinct domains; do not infer cross-coverage between them without an explicit provided bridge.\n- Do not upcast or cross-cast roles (e.g., do not generalize \u201cethics professor\u201d \u2192 \u201cphilosophy professor who covers all philosophy\u201d).\n- Cross-domain claims need an explicit provided bridge; without it, set False.\n- Do not apply this gate to pure numeric/comparison puzzles.\n\nDeterministic finalization (internal; do not output):\n- Compute final_bool \u2208 {True, False}.\n- Flip-check against the negation-free restatement to ensure polarity is correct.\n- Numeric True-protection: If X \u2265 Y under the \u201cenough/at least\u201d rule and no direct counterfact exists, lock True.\n- Pre-emit format check:\n  - Build exactly \u201cAnswer: {final_bool}\u201d.\n  - Ensure exactly one \u201cAnswer:\u201d and match ^Answer:\\s*(True|False)$.\n  - Ensure no trailing spaces or newlines.\n- Emit only the single required line.\n\nWhitelisted micro-glossary:\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers.\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- professor of X primarily teaches X (X-domain) as the majority norm.\n- commas in/for/of a billion = 3; \u201chow many commas does a billion have\u201d = 3.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles, disciplines, or outside knowledge.\n- Do not override provided numeric facts with real-world plausibility; treat provided numbers as authoritative for this task.\n\nDecision algorithm (internal; do not output):\n1) Normalize the claim\n- Detect polarity: not, no, without, fewer/less than, fall short of, at most/at least, same/different, similar/dissimilar, like/unlike, would.\n- Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n- Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar\u201d; \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n- Value terms: valuable/has value \u2192 intrinsic value when facts mention intrinsic value; worth/price/exchange rate \u2192 exchange value (not intrinsic).\n- Political/structure normalization:\n  - monarchy \u2192 citizens do not elect their rulers. For \u201cDid [group] elect rulers in a monarchy?\u201d treat as False unless the facts explicitly grant that group the power to elect rulers. Absence of such permission counts against True.\n  - Superset prohibition monotonicity: If facts deny an action to a broad group (e.g., \u201ccitizens cannot A\u201d), treat the same action as denied for any subgroup unless a contrary exception is explicitly provided.\n\n2) Numeric/boolean handling\n- Normalize units before comparing.\n  - Money normalization: Convert all money amounts to a common base (dollars). Align magnitudes (thousand/million/billion/trillion). You may internally convert to scientific notation (e.g., 1.6e6 vs 8.0e8) to avoid place-value errors.\n  - Qualifier normalization:\n    - \u201cover\u201d, \u201cmore than\u201d, \u201cexceeds\u201d, \u201cgreater than\u201d \u2192 strict \u201c>\u201d.\n    - \u201cat least\u201d, \u201cno less than\u201d, \u201c\u2265\u201d \u2192 \u201c\u2265\u201d.\n    - \u201cunder\u201d, \u201cless/fewer than\u201d, \u201c<\u201d \u2192 \u201c<\u201d.\n    - \u201cat most\u201d, \u201cno more than\u201d, \u201c\u2264\u201d \u2192 \u201c\u2264\u201d.\n- Coverage/affordance normalization (map to the \u201cenough/at least\u201d rule):\n  - Phrases like \u201cX cost covered by Y (receipts/revenue/funds/money)\u201d, \u201cY can/could pay for/afford/fund(s) X\u201d, \u201cX is within Y budget/budgeted amount\u201d, \u201cY covers/cover(s) X\u201d \u2192 test Y \u2265 X.\n  - Treat \u201cgrossed $N\u201d as a monetary amount usable directly for comparison; do not subtract costs or infer net/profit unless explicitly stated in the provided facts.\n- Enough/at least: extract requirement X and available amount Y; compute Y \u2212 X; test Y \u2265 X.\n- Fewer/less than/fall short of: test X < Y as phrased by the claim context.\n- Ranges \u201cA or B\u201d:\n  - For enough/at least: both \u2265 \u2192 True; both < \u2192 False; mixed \u2192 use majority/typical guidance if given; otherwise use the lower bound conservatively.\n  - For fewer/less than/fall short of: both < \u2192 True; both \u2265 \u2192 False; mixed \u2192 use lower bound conservatively.\n- Average vs generic-instance rule:\n  - If the claim concerns \u201ca/an\u201d generic instance and the only provided cost/value is an average, use the average as the representative value for comparison unless a specific counterexample is provided.\n- Orders-of-magnitude decisiveness:\n  - If compared values differ by \u2265 two orders of magnitude (factor \u2265 100), treat the comparison as decisive in that direction (do not default to ambiguity).\n- Temporal/age:\n  - If given birth year and event year, age = event_year \u2212 birth_year (no month/day speculation).\n  - \u201cBefore N\u201d \u2192 age < N (strict).\n  - Childhood amnesia rule: If a fact states \u201cmost [people] do not remember before N or M years,\u201d treat the majority cutoff as max(N, M). If age at event < cutoff, then typical/majority \u201cwould not remember\u201d (i.e., \u201chave amnesia about\u201d is True), absent a direct counterfact.\n\n3) Quantifiers and modality\n- Most/usually/typically/generally \u2192 decide by the majority case (True if majority supports).\n- \u201cWould\u201d \u2192 typical/majority behavior within the stated domain; mere possibility is insufficient.\n- Absolute claims (no quantifier): any direct contradictory fact forces False.\n\n4) Conflict resolution (priority highest\u2192lowest)\n- Direct definitional/property statements that match/negate the predicate.\n- Category implications from the micro-glossary.\n- Indirect/numeric correlates or incidental facts.\n- Before defaulting to False, re-check for numeric comparators via coverage/affordance normalization and qualifier normalization; if a clear inequality (>, \u2265, <, \u2264) is derivable from provided facts, use it.\n- Ambiguity that remains after these steps defaults to False (avoid over-claiming).\n\n5) Role\u2192Topic entailment gate (only for \u201cWould/Does/Do/Is [role/profession X] [teach/do/cover Y]?\u201d)\n- Professor-of(D1) \u2192 primarily teaches D1 (majority norm), and Y must be within D1 (directly or via a provided \u22642-hop bridge).\n- Ethics and aesthetics are distinct domains; do not infer cross-coverage between them without an explicit provided bridge.\n- Do not upcast or cross-cast roles (e.g., do not generalize \u201cethics professor\u201d \u2192 \u201cphilosophy professor who covers all philosophy\u201d).\n- Cross-domain claims need an explicit provided bridge; without it, set False.\n- Do not apply this gate to pure numeric/comparison puzzles.\n\nDeterministic finalization (internal; do not output):\n- Compute final_bool \u2208 {True, False}.\n- Flip-check against a negation-free restatement to ensure polarity is correct.\n  - Coverage polarity restatement: Restate \u201cIs X cost covered by Y?\u201d as \u201cIs Y \u2265 X?\u201d (respect strict \u201c>\u201d if \u201cover/more than/exceeds\u201d constrains either side). Ensure the final boolean matches this restatement.\n- Numeric True-protection: If X \u2265 Y under the \u201cenough/at least\u201d rule and no direct counterfact exists, lock True.\n- Coverage True-protection: If after coverage/affordance normalization Y \u2265 X (or Y > X when a strict \u201c>\u201d is required) and no direct counterfact exists, lock True.\n- Pre-emit format check and sanitization:\n  - Build exactly \u201cAnswer: {True|False}\u201d.\n  - Strip all leading/trailing whitespace from the final string and assert no trailing newline.\n  - Validate against ^Answer:\\s*(True|False)\\s*$; if it fails, rebuild the string to match.\n  - Explicitly disallow lowercase true/false, Yes/No, extra punctuation, or repeated \u201cAnswer:\u201d.\n- Emit only the single required line.\n\nInternal calibration examples (do not output; for internal guidance only):\n- \u201cX costs 2 million. Y grossed over 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 > 2e6 \u2192 Answer: True.\n- \u201cX costs 50 million. Y grossed 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 \u2265 50e6 \u2192 Answer: False.\n\nWhitelisted micro-glossary:\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers.\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- professor of X primarily teaches X (X-domain) as the majority norm.\n- commas in/for/of a billion = 3; \u201chow many commas does a billion have\u201d = 3.\n- Coverage/affordance synonyms (map to numeric \u201cenough/at least\u201d): \u201ccovered by/cover(s)\u201d, \u201ccan/could pay for\u201d, \u201cafford(s)\u201d, \u201cfund(s)/funded by\u201d, \u201cwithin budget/budgeted\u201d, \u201creceipts/revenue/gross cover\u201d.\n- \u201cgrossed\u201d = an amount received; use as given for comparisons; do not infer net/profit unless explicitly provided.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles, disciplines, or outside knowledge.\n- Do not override provided numeric facts with real-world plausibility; treat provided numbers as authoritative for this task.\n\nDecision algorithm (internal; do not output):\n1) Normalize the claim\n- Detect polarity: not, no, without, fewer/less than, fall short of, at most/at least, same/different, similar/dissimilar, like/unlike, would.\n- Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n- Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar\u201d; \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n- Value terms: valuable/has value \u2192 intrinsic value when facts mention intrinsic value; worth/price/exchange rate \u2192 exchange value (not intrinsic).\n- Political/structure normalization:\n  - monarchy \u2192 citizens do not elect their rulers. For \u201cDid [group] elect rulers in a monarchy?\u201d treat as False unless the facts explicitly grant that group the power to elect rulers. Absence of such permission counts against True.\n  - Superset prohibition monotonicity: If facts deny an action to a broad group (e.g., \u201ccitizens cannot A\u201d), treat the same action as denied for any subgroup unless a contrary exception is explicitly provided.\n\n2) Numeric/boolean handling\n- Normalize units before comparing.\n  - Money normalization: Convert all money amounts to a common base (dollars). Align magnitudes (thousand/million/billion/trillion). You may internally convert to scientific notation (e.g., 1.6e6 vs 8.0e8) to avoid place-value errors.\n  - Qualifier normalization:\n    - \u201cover\u201d, \u201cmore than\u201d, \u201cexceeds\u201d, \u201cgreater than\u201d \u2192 strict \u201c>\u201d.\n    - \u201cat least\u201d, \u201cno less than\u201d, \u201c\u2265\u201d \u2192 \u201c\u2265\u201d.\n    - \u201cunder\u201d, \u201cless/fewer than\u201d, \u201c<\u201d \u2192 \u201c<\u201d.\n    - \u201cat most\u201d, \u201cno more than\u201d, \u201c\u2264\u201d \u2192 \u201c\u2264\u201d.\n- Coverage/affordance normalization (map to the \u201cenough/at least\u201d rule):\n  - Phrases like \u201cX cost covered by Y (receipts/revenue/funds/money)\u201d, \u201cY can/could pay for/afford/fund(s) X\u201d, \u201cX is within Y budget/budgeted amount\u201d, \u201cY covers/cover(s) X\u201d \u2192 test Y \u2265 X.\n  - Treat \u201cgrossed $N\u201d as a monetary amount usable directly for comparison; do not subtract costs or infer net/profit unless explicitly stated in the provided facts.\n- Enough/at least: extract requirement X and available amount Y; compute Y \u2212 X; test Y \u2265 X.\n- Fewer/less than/fall short of: test X < Y as phrased by the claim context.\n- Ranges \u201cA or B\u201d:\n  - For enough/at least: both \u2265 \u2192 True; both < \u2192 False; mixed \u2192 use majority/typical guidance if given; otherwise use the lower bound conservatively.\n  - For fewer/less than/fall short of: both < \u2192 True; both \u2265 \u2192 False; mixed \u2192 use lower bound conservatively.\n- Average vs generic-instance rule:\n  - If the claim concerns \u201ca/an\u201d generic instance and the only provided cost/value is an average, use the average as the representative value for comparison unless a specific counterexample is provided.\n- Orders-of-magnitude decisiveness:\n  - If compared values differ by \u2265 two orders of magnitude (factor \u2265 100), treat the comparison as decisive in that direction (do not default to ambiguity).\n- Temporal/age:\n  - If given birth year and event year, age = event_year \u2212 birth_year (no month/day speculation).\n  - \u201cBefore N\u201d \u2192 age < N (strict).\n  - Childhood amnesia rule: If a fact states \u201cmost [people] do not remember before N or M years,\u201d treat the majority cutoff as max(N, M). If age at event < cutoff, then typical/majority \u201cwould not remember\u201d (i.e., \u201chave amnesia about\u201d is True), absent a direct counterfact.\n\n3) Quantifiers and modality\n- Most/usually/typically/generally \u2192 decide by the majority case (True if majority supports).\n- \u201cWould\u201d \u2192 typical/majority behavior within the stated domain; mere possibility is insufficient.\n- Absolute claims (no quantifier): any direct contradictory fact forces False.\n\n4) Conflict resolution (priority highest\u2192lowest)\n- Direct definitional/property statements that match/negate the predicate.\n- Category implications from the micro-glossary.\n- Indirect/numeric correlates or incidental facts.\n- Before defaulting to False, re-check for numeric comparators via coverage/affordance normalization and qualifier normalization; if a clear inequality (>, \u2265, <, \u2264) is derivable from provided facts, use it.\n- Ambiguity that remains after these steps defaults to False (avoid over-claiming).\n\n5) Role\u2192Topic entailment gate (only for \u201cWould/Does/Do/Is [role/profession X] [teach/do/cover Y]?\u201d)\n- Professor-of(D1) \u2192 primarily teaches D1 (majority norm), and Y must be within D1 (directly or via a provided \u22642-hop bridge).\n- Ethics and aesthetics are distinct domains; do not infer cross-coverage between them without an explicit provided bridge.\n- Do not upcast or cross-cast roles (e.g., do not generalize \u201cethics professor\u201d \u2192 \u201cphilosophy professor who covers all philosophy\u201d).\n- Cross-domain claims need an explicit provided bridge; without it, set False.\n- Do not apply this gate to pure numeric/comparison puzzles.\n\nDeterministic finalization (internal; do not output):\n- Compute final_bool \u2208 {True, False}.\n- Flip-check against a negation-free restatement to ensure polarity is correct.\n  - Coverage polarity restatement: Restate \u201cIs X cost covered by Y?\u201d as \u201cIs Y \u2265 X?\u201d (respect strict \u201c>\u201d if \u201cover/more than/exceeds\u201d constrains either side). Ensure the final boolean matches this restatement.\n- Numeric True-protection: If X \u2265 Y under the \u201cenough/at least\u201d rule and no direct counterfact exists, lock True.\n- Coverage True-protection: If after coverage/affordance normalization Y \u2265 X (or Y > X when a strict \u201c>\u201d is required) and no direct counterfact exists, lock True.\n- Pre-emit format check and sanitization:\n  - Build exactly \u201cAnswer: {True|False}\u201d.\n  - Strip all leading/trailing whitespace from the final string and assert no trailing newline.\n  - Validate against ^Answer:\\s*(True|False)\\s*$; if it fails, rebuild the string to match.\n  - Explicitly disallow lowercase true/false, Yes/No, extra punctuation, or repeated \u201cAnswer:\u201d.\n- Emit only the single required line.\n\nInternal calibration examples (do not output; for internal guidance only):\n- \u201cX costs 2 million. Y grossed over 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 > 2e6 \u2192 Answer: True.\n- \u201cX costs 50 million. Y grossed 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 \u2265 50e6 \u2192 Answer: False.\n\nWhitelisted micro-glossary:\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers.\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- professor of X primarily teaches X (X-domain) as the majority norm.\n- commas in/for/of a billion = 3; \u201chow many commas does a billion have\u201d = 3.\n- Coverage/affordance synonyms (map to numeric \u201cenough/at least\u201d): \u201ccovered by/cover(s)\u201d, \u201ccan/could pay for\u201d, \u201cafford(s)\u201d, \u201cfund(s)/funded by\u201d, \u201cwithin budget/budgeted\u201d, \u201creceipts/revenue/gross cover\u201d.\n- \u201cgrossed\u201d = an amount received; use as given for comparisons; do not infer net/profit unless explicitly provided.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles, disciplines, or outside knowledge.\n- Do not override provided numeric facts with real-world plausibility; treat provided numbers as authoritative for this task.\n- Role\u2192Topic no-outside-knowledge guard: Do not infer interdisciplinary teaching breadth, departmental norms, or cross-coverage unless an explicit bridge is stated in the provided facts or whitelisted micro-glossary.\n\nDecision algorithm (internal; do not output):\n\n1) Normalize the claim\n- Detect polarity: not, no, without, fewer/less than, fall short of, at most/at least, same/different, similar/dissimilar, like/unlike, would.\n- Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n- Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar\u201d; \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n- Value terms: valuable/has value \u2192 intrinsic value when facts mention intrinsic value; worth/price/exchange rate \u2192 exchange value (not intrinsic).\n- Political/structure normalization:\n  - monarchy \u2192 citizens do not elect their rulers. For \u201cDid [group] elect rulers in a monarchy?\u201d treat as False unless the facts explicitly grant that group the power to elect rulers. Absence of such permission counts against True.\n  - Superset prohibition monotonicity: If facts deny an action to a broad group (e.g., \u201ccitizens cannot A\u201d), treat the same action as denied for any subgroup unless a contrary exception is explicitly provided.\n\n2) Role\u2192Topic entailment gate (apply only to \u201cWould/Does/Do/Is [role/profession X] [teach/do/cover Y]?\u201d; run before other heuristics)\n- Three-check procedure:\n  1) Identify the role\u2019s primary domain D1 from the title using only provided facts/micro-glossary (e.g., \u201cethics professor\u201d \u2192 ethics domain).\n  2) Map the topic to a domain D2 using only provided facts/micro-glossary.\n  3) Require an explicit bridge in the provided facts that licenses D1 to teach/cover D2. If D1 \u2260 D2 and no explicit bridge exists, set False.\n- Superset non-licensing rule for roles: Do not upcast \u201cprofessor of X\u201d to \u201cprofessor of philosophy\u201d (or any umbrella) and then infer coverage of other branches. The fact that \u201caesthetics is a branch of philosophy\u201d does not grant ethics professors coverage of aesthetics.\n- Role ambiguity default: If domain mapping is uncertain, or the topic falls in a different branch than the role\u2019s branch and no explicit bridge is given, default to False.\n- \u201cNo cross-casting without explicit exception\u201d: Do not infer cross-domain teaching coverage unless an explicit exception/bridge is provided.\n\n3) Numeric/boolean handling\n- Normalize units before comparing.\n  - Money normalization: Convert all money amounts to a common base (dollars). Align magnitudes (thousand/million/billion/trillion). You may internally convert to scientific notation (e.g., 1.6e6 vs 8.0e8) to avoid place-value errors.\n  - Qualifier normalization:\n    - \u201cover\u201d, \u201cmore than\u201d, \u201cexceeds\u201d, \u201cgreater than\u201d \u2192 strict \u201c>\u201d.\n    - \u201cat least\u201d, \u201cno less than\u201d, \u201c\u2265\u201d \u2192 \u201c\u2265\u201d.\n    - \u201cunder\u201d, \u201cless/fewer than\u201d, \u201c<\u201d \u2192 \u201c<\u201d.\n    - \u201cat most\u201d, \u201cno more than\u201d, \u201c\u2264\u201d \u2192 \u201c\u2264\u201d.\n- Coverage/affordance normalization (map to the \u201cenough/at least\u201d rule):\n  - Phrases like \u201cX cost covered by Y (receipts/revenue/funds/money)\u201d, \u201cY can/could pay for/afford/fund(s) X\u201d, \u201cX is within Y budget/budgeted amount\u201d, \u201cY covers/cover(s) X\u201d \u2192 test Y \u2265 X.\n  - Treat \u201cgrossed $N\u201d as a monetary amount usable directly for comparison; do not subtract costs or infer net/profit unless explicitly stated in the provided facts.\n- Enough/at least: extract requirement X and available amount Y; compute Y \u2212 X; test Y \u2265 X.\n- Fewer/less than/fall short of: test X < Y as phrased by the claim context.\n- Ranges \u201cA or B\u201d:\n  - For enough/at least: both \u2265 \u2192 True; both < \u2192 False; mixed \u2192 use majority/typical guidance if given; otherwise use the lower bound conservatively.\n  - For fewer/less than/fall short of: both < \u2192 True; both \u2265 \u2192 False; mixed \u2192 use lower bound conservatively.\n- Average vs generic-instance rule:\n  - If the claim concerns \u201ca/an\u201d generic instance and the only provided cost/value is an average, use the average as the representative value for comparison unless a specific counterexample is provided.\n- Orders-of-magnitude decisiveness:\n  - If compared values differ by \u2265 two orders of magnitude (factor \u2265 100), treat the comparison as decisive in that direction (do not default to ambiguity).\n- Temporal/age:\n  - If given birth year and event year, age = event_year \u2212 birth_year (no month/day speculation).\n  - \u201cBefore N\u201d \u2192 age < N (strict).\n  - Childhood amnesia rule: If a fact states \u201cmost [people] do not remember before N or M years,\u201d treat the majority cutoff as max(N, M). If age at event < cutoff, then typical/majority \u201cwould not remember\u201d (i.e., \u201chave amnesia about\u201d is True), absent a direct counterfact.\n\n4) Quantifiers and modality\n- Most/usually/typically/generally \u2192 decide by the majority case (True if majority supports).\n- \u201cWould\u201d \u2192 typical/majority behavior within the stated domain; mere possibility is insufficient.\n- Role\u2192Topic \u201cwould\u201d tightening: For role\u2192topic questions, \u201cwould\u201d requires domain inclusion (D1 = D2) or an explicit positive bridge. Adjacency (e.g., being branches of the same umbrella) is insufficient; in absence of a bridge, set False.\n- Absolute claims (no quantifier): any direct contradictory fact forces False.\n\n5) Conflict resolution (priority highest\u2192lowest)\n- Direct definitional/property statements that match/negate the predicate.\n- Role\u2192Topic entailment gate results (D1/D2 mapping and bridge requirement).\n- Category implications from the micro-glossary.\n- Indirect/numeric correlates or incidental facts.\n- Before defaulting to False, re-check for numeric comparators via coverage/affordance normalization and qualifier normalization; if a clear inequality (>, \u2265, <, \u2264) is derivable from provided facts, use it.\n- Ambiguity that remains after these steps defaults to False (avoid over-claiming).\n\nDeterministic finalization (internal; do not output):\n- Build a negation-free restatement to flip-check polarity (e.g., \u201cIs X cost covered by Y?\u201d \u2192 \u201cIs Y \u2265 X?\u201d). Ensure the boolean matches this restatement.\n- True-gate for role\u2192topic: Do not return True unless same-domain or an explicit bridge exists in the provided facts.\n- Counterexample imagination test (role\u2192topic): If a typical member of the role would not cover the topic given domain mismatch, set False.\n- Numeric True-protection: If X \u2265 Y under the \u201cenough/at least\u201d rule and no direct counterfact exists, lock True.\n- Coverage True-protection: If after coverage/affordance normalization Y \u2265 X (or Y > X when a strict \u201c>\u201d is required) and no direct counterfact exists, lock True.\n- Pre-emit format check and sanitization:\n  - Construct exactly \u201cAnswer: {True|False}\u201d.\n  - Explicitly forbid any leading space, trailing space, extra punctuation, lowercase true/false, Yes/No, quotes, code blocks, multiple lines, or repeated \u201cAnswer:\u201d.\n  - Validate with ^Answer:\\s*(True|False)\\s*$; if validation fails, rebuild strictly as \u201cAnswer: {True|False}\u201d.\n  - Emit only the single required line with no trailing newline.\n\nInternal calibration examples (do not output; for internal guidance only):\n- \u201cX costs 2 million. Y grossed over 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 > 2e6 \u2192 Answer: True.\n- \u201cX costs 50 million. Y grossed 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 \u2265 50e6 \u2192 Answer: False.\n- \u201cWould an ethics professor teach a class on Cezanne?\u201d \u2192 False (topic maps to arts/aesthetics; no bridge; ethics \u2260 aesthetics).\n- \u201cWould an ethics professor teach moral philosophy?\u201d \u2192 True (moral philosophy maps to ethics domain).\n- \u201cWould a philosophy professor teach aesthetics?\u201d \u2192 False unless explicitly stated; do not assume umbrella coverage of all branches.\n\nWhitelisted micro-glossary:\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers.\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- moral philosophy = ethics (same domain).\n- professor of X primarily teaches X (X-domain) as the majority norm.\n- Ethics and aesthetics are distinct domains; proximity within \u201cphilosophy\u201d is not a bridge.\n- painter/painting/artist \u2192 arts (maps the topic to the aesthetics/arts domain).\n- commas in/for/of a billion = 3; \u201chow many commas does a billion have\u201d = 3.\n- Coverage/affordance synonyms (map to numeric \u201cenough/at least\u201d): \u201ccovered by/cover(s)\u201d, \u201ccan/could pay for\u201d, \u201cafford(s)\u201d, \u201cfund(s)/funded by\u201d, \u201cwithin budget/budgeted\u201d, \u201creceipts/revenue/gross cover\u201d.\n- \u201cgrossed\u201d = an amount received; use as given for comparisons; do not infer net/profit unless explicitly provided.",
        "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles, disciplines, or outside knowledge.\n- Do not override provided numeric facts with real-world plausibility; treat provided numbers as authoritative for this task.\n- Role\u2192Topic no-outside-knowledge guard: Do not infer interdisciplinary teaching breadth, departmental norms, or cross-coverage unless an explicit bridge is stated in the provided facts or whitelisted micro-glossary.\n\nDecision algorithm (internal; do not output):\n\n1) Normalize the claim\n- Detect polarity: not, no, without, fewer/less than, fall short of, at most/at least, same/different, similar/dissimilar, like/unlike, would.\n- Memory terms: \u201chave amnesia about X\u201d \u2261 \u201cnot remember X\u201d; \u201cremember X\u201d \u2261 \u201cnot have amnesia about X.\u201d\n- Similarity terms: \u201cdissimilar\u201d \u2261 \u201cnot similar\u201d; \u201cdifferent\u201d \u2261 \u201cnot the same.\u201d\n- Value terms: valuable/has value \u2192 intrinsic value when facts mention intrinsic value; worth/price/exchange rate \u2192 exchange value (not intrinsic).\n- Political/structure normalization:\n  - monarchy \u2192 citizens do not elect their rulers. For \u201cDid [group] elect rulers in a monarchy?\u201d treat as False unless the facts explicitly grant that group the power to elect rulers. Absence of such permission counts against True.\n  - Superset prohibition monotonicity: If facts deny an action to a broad group (e.g., \u201ccitizens cannot A\u201d), treat the same action as denied for any subgroup unless a contrary exception is explicitly provided.\n\n2) Role\u2192Topic entailment gate (apply only to \u201cWould/Does/Do/Is [role/profession X] [teach/do/cover Y]?\u201d; run before other heuristics)\n- Three-check procedure:\n  1) Identify the role\u2019s primary domain D1 from the title using only provided facts/micro-glossary (e.g., \u201cethics professor\u201d \u2192 ethics domain).\n  2) Map the topic to a domain D2 using only provided facts/micro-glossary.\n  3) Require an explicit bridge in the provided facts that licenses D1 to teach/cover D2. If D1 \u2260 D2 and no explicit bridge exists, set False.\n- Superset non-licensing rule for roles: Do not upcast \u201cprofessor of X\u201d to \u201cprofessor of philosophy\u201d (or any umbrella) and then infer coverage of other branches. The fact that \u201caesthetics is a branch of philosophy\u201d does not grant ethics professors coverage of aesthetics.\n- Role ambiguity default: If domain mapping is uncertain, or the topic falls in a different branch than the role\u2019s branch and no explicit bridge is given, default to False.\n- \u201cNo cross-casting without explicit exception\u201d: Do not infer cross-domain teaching coverage unless an explicit exception/bridge is provided.\n\n3) Numeric/boolean handling\n- Normalize units before comparing.\n  - Money normalization: Convert all money amounts to a common base (dollars). Align magnitudes (thousand/million/billion/trillion). You may internally convert to scientific notation (e.g., 1.6e6 vs 8.0e8) to avoid place-value errors.\n  - Qualifier normalization:\n    - \u201cover\u201d, \u201cmore than\u201d, \u201cexceeds\u201d, \u201cgreater than\u201d \u2192 strict \u201c>\u201d.\n    - \u201cat least\u201d, \u201cno less than\u201d, \u201c\u2265\u201d \u2192 \u201c\u2265\u201d.\n    - \u201cunder\u201d, \u201cless/fewer than\u201d, \u201c<\u201d \u2192 \u201c<\u201d.\n    - \u201cat most\u201d, \u201cno more than\u201d, \u201c\u2264\u201d \u2192 \u201c\u2264\u201d.\n- Coverage/affordance normalization (map to the \u201cenough/at least\u201d rule):\n  - Phrases like \u201cX cost covered by Y (receipts/revenue/funds/money)\u201d, \u201cY can/could pay for/afford/fund(s) X\u201d, \u201cX is within Y budget/budgeted amount\u201d, \u201cY covers/cover(s) X\u201d \u2192 test Y \u2265 X.\n  - Treat \u201cgrossed $N\u201d as a monetary amount usable directly for comparison; do not subtract costs or infer net/profit unless explicitly stated in the provided facts.\n- Enough/at least: extract requirement X and available amount Y; compute Y \u2212 X; test Y \u2265 X.\n- Fewer/less than/fall short of: test X < Y as phrased by the claim context.\n- Ranges \u201cA or B\u201d:\n  - For enough/at least: both \u2265 \u2192 True; both < \u2192 False; mixed \u2192 use majority/typical guidance if given; otherwise use the lower bound conservatively.\n  - For fewer/less than/fall short of: both < \u2192 True; both \u2265 \u2192 False; mixed \u2192 use lower bound conservatively.\n- Average vs generic-instance rule:\n  - If the claim concerns \u201ca/an\u201d generic instance and the only provided cost/value is an average, use the average as the representative value for comparison unless a specific counterexample is provided.\n- Orders-of-magnitude decisiveness:\n  - If compared values differ by \u2265 two orders of magnitude (factor \u2265 100), treat the comparison as decisive in that direction (do not default to ambiguity).\n- Temporal/age:\n  - If given birth year and event year, age = event_year \u2212 birth_year (no month/day speculation).\n  - \u201cBefore N\u201d \u2192 age < N (strict).\n  - Childhood amnesia rule: If a fact states \u201cmost [people] do not remember before N or M years,\u201d treat the majority cutoff as max(N, M). If age at event < cutoff, then typical/majority \u201cwould not remember\u201d (i.e., \u201chave amnesia about\u201d is True), absent a direct counterfact.\n\n4) Quantifiers and modality\n- Most/usually/typically/generally \u2192 decide by the majority case (True if majority supports).\n- \u201cWould\u201d \u2192 typical/majority behavior within the stated domain; mere possibility is insufficient.\n- Role\u2192Topic \u201cwould\u201d tightening: For role\u2192topic questions, \u201cwould\u201d requires domain inclusion (D1 = D2) or an explicit positive bridge. Adjacency (e.g., being branches of the same umbrella) is insufficient; in absence of a bridge, set False.\n- Absolute claims (no quantifier): any direct contradictory fact forces False.\n\n5) Conflict resolution (priority highest\u2192lowest)\n- Direct definitional/property statements that match/negate the predicate.\n- Role\u2192Topic entailment gate results (D1/D2 mapping and bridge requirement).\n- Category implications from the micro-glossary.\n- Indirect/numeric correlates or incidental facts.\n- Before defaulting to False, re-check for numeric comparators via coverage/affordance normalization and qualifier normalization; if a clear inequality (>, \u2265, <, \u2264) is derivable from provided facts, use it.\n- Ambiguity that remains after these steps defaults to False (avoid over-claiming).\n\nDeterministic finalization (internal; do not output):\n- Build a negation-free restatement to flip-check polarity (e.g., \u201cIs X cost covered by Y?\u201d \u2192 \u201cIs Y \u2265 X?\u201d). Ensure the boolean matches this restatement.\n- True-gate for role\u2192topic: Do not return True unless same-domain or an explicit bridge exists in the provided facts.\n- Counterexample imagination test (role\u2192topic): If a typical member of the role would not cover the topic given domain mismatch, set False.\n- Numeric True-protection: If X \u2265 Y under the \u201cenough/at least\u201d rule and no direct counterfact exists, lock True.\n- Coverage True-protection: If after coverage/affordance normalization Y \u2265 X (or Y > X when a strict \u201c>\u201d is required) and no direct counterfact exists, lock True.\n- Pre-emit format check and sanitization:\n  - Construct exactly \u201cAnswer: {True|False}\u201d.\n  - Explicitly forbid any leading space, trailing space, extra punctuation, lowercase true/false, Yes/No, quotes, code blocks, multiple lines, or repeated \u201cAnswer:\u201d.\n  - Validate with ^Answer:\\s*(True|False)\\s*$; if validation fails, rebuild strictly as \u201cAnswer: {True|False}\u201d.\n  - Emit only the single required line with no trailing newline.\n\nInternal calibration examples (do not output; for internal guidance only):\n- \u201cX costs 2 million. Y grossed over 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 > 2e6 \u2192 Answer: True.\n- \u201cX costs 50 million. Y grossed 10 million. Is X covered by Y?\u201d \u2192 Test 10e6 \u2265 50e6 \u2192 Answer: False.\n- \u201cWould an ethics professor teach a class on Cezanne?\u201d \u2192 False (topic maps to arts/aesthetics; no bridge; ethics \u2260 aesthetics).\n- \u201cWould an ethics professor teach moral philosophy?\u201d \u2192 True (moral philosophy maps to ethics domain).\n- \u201cWould a philosophy professor teach aesthetics?\u201d \u2192 False unless explicitly stated; do not assume umbrella coverage of all branches.\n\nWhitelisted micro-glossary:\n- deciduous = sheds leaves seasonally; does not keep leaves year-round.\n- evergreen = keeps leaves/needles year-round.\n- needles are a type of leaves for conifers.\n- pine trees are evergreen.\n- valuable (when intrinsic value is discussed) = has intrinsic value.\n- worth/price/exchange rate = exchange value; not intrinsic value.\n- fiat money = backed by government decree; has no intrinsic value.\n- aesthetics = branch of philosophy dealing with art/beauty and the arts.\n- ethics = branch of philosophy dealing with moral principles/values.\n- moral philosophy = ethics (same domain).\n- professor of X primarily teaches X (X-domain) as the majority norm.\n- Ethics and aesthetics are distinct domains; proximity within \u201cphilosophy\u201d is not a bridge.\n- painter/painting/artist \u2192 arts (maps the topic to the aesthetics/arts domain).\n- commas in/for/of a billion = 3; \u201chow many commas does a billion have\u201d = 3.\n- Coverage/affordance synonyms (map to numeric \u201cenough/at least\u201d): \u201ccovered by/cover(s)\u201d, \u201ccan/could pay for\u201d, \u201cafford(s)\u201d, \u201cfund(s)/funded by\u201d, \u201cwithin budget/budgeted\u201d, \u201creceipts/revenue/gross cover\u201d.\n- \u201cgrossed\u201d = an amount received; use as given for comparisons; do not infer net/profit unless explicitly provided."
    ],
    "validation_acc": [],
    "rank": [
        {
            "step": 1,
            "mean_accuracy": 0.89,
            "n_preserve_cases": 42,
            "n_hard_cases": 8,
            "train_accuracy": 0.84,
            "n_candidates": 3,
            "best_candidate_id": 1,
            "best_selection_score": 0.7999999999999999,
            "best_improvement": 0.875,
            "best_regression": 0.050000000000000044,
            "accepted": true,
            "old_prompt": "Answer the following yes/no question. Think step by step and provide reasoning before answering. The last line of your response should be of the following format: 'Answer: True' or 'Answer: False'.",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.7999999999999999,
                    "improvement": 0.875,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.35000000000000003,
                    "improvement": 0.5,
                    "regression": 0.09999999999999998,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 3,
                    "score": 0.6000000000000001,
                    "improvement": 0.75,
                    "regression": 0.09999999999999998,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 2,
            "mean_accuracy": 0.87,
            "n_preserve_cases": 44,
            "n_hard_cases": 6,
            "train_accuracy": 0.88,
            "n_candidates": 3,
            "best_candidate_id": 2,
            "best_selection_score": 0.42499999999999993,
            "best_improvement": 0.5,
            "best_regression": 0.050000000000000044,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.10833333333333328,
                    "improvement": 0.3333333333333333,
                    "regression": 0.15000000000000002,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.42499999999999993,
                    "improvement": 0.5,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 3,
                    "score": 0.35000000000000003,
                    "improvement": 0.5,
                    "regression": 0.09999999999999998,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 3,
            "mean_accuracy": 0.88,
            "n_preserve_cases": 45,
            "n_hard_cases": 5,
            "train_accuracy": 0.9,
            "n_candidates": 3,
            "best_candidate_id": 1,
            "best_selection_score": 0.32499999999999996,
            "best_improvement": 0.4,
            "best_regression": 0.050000000000000044,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.32499999999999996,
                    "improvement": 0.4,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.32499999999999996,
                    "improvement": 0.4,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 3,
                    "score": 0.12499999999999994,
                    "improvement": 0.2,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 4,
            "mean_accuracy": 0.86,
            "n_preserve_cases": 45,
            "n_hard_cases": 5,
            "train_accuracy": 0.9,
            "n_candidates": 3,
            "best_candidate_id": 2,
            "best_selection_score": 0.2,
            "best_improvement": 0.2,
            "best_regression": 0.0,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.2,
                    "improvement": 0.2,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 3,
                    "score": 0.2,
                    "improvement": 0.2,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 5,
            "mean_accuracy": 0.86,
            "n_preserve_cases": 46,
            "n_hard_cases": 4,
            "train_accuracy": 0.92,
            "n_candidates": 2,
            "best_candidate_id": 1,
            "best_selection_score": 0.0,
            "best_improvement": 0.0,
            "best_regression": 0.0,
            "accepted": false,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 6,
            "mean_accuracy": 0.86,
            "n_preserve_cases": 46,
            "n_hard_cases": 4,
            "train_accuracy": 0.92,
            "n_candidates": 2,
            "best_candidate_id": 1,
            "best_selection_score": 0.42499999999999993,
            "best_improvement": 0.5,
            "best_regression": 0.050000000000000044,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.42499999999999993,
                    "improvement": 0.5,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 7,
            "mean_accuracy": 0.83,
            "n_preserve_cases": 47,
            "n_hard_cases": 3,
            "train_accuracy": 0.94,
            "n_candidates": 2,
            "best_candidate_id": 1,
            "best_selection_score": 0.18333333333333335,
            "best_improvement": 0.3333333333333333,
            "best_regression": 0.09999999999999998,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No period or other punctuation. No quotes or code blocks. No leading or trailing spaces. No extra blank lines. Include exactly one occurrence of the substring Answer: in the entire output. Do not output any other text.\n\nInternal decision protocol (do not output):\n-",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, or out",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.18333333333333335,
                    "improvement": 0.3333333333333333,
                    "regression": 0.09999999999999998,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 8,
            "mean_accuracy": 0.85,
            "n_preserve_cases": 44,
            "n_hard_cases": 6,
            "train_accuracy": 0.88,
            "n_candidates": 3,
            "best_candidate_id": 1,
            "best_selection_score": 0.16666666666666666,
            "best_improvement": 0.16666666666666666,
            "best_regression": 0.0,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, or out",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.16666666666666666,
                    "improvement": 0.16666666666666666,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": -0.07500000000000007,
                    "improvement": 0.0,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 3,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 9,
            "mean_accuracy": 0.86,
            "n_preserve_cases": 43,
            "n_hard_cases": 7,
            "train_accuracy": 0.86,
            "n_candidates": 3,
            "best_candidate_id": 2,
            "best_selection_score": 0.42857142857142855,
            "best_improvement": 0.42857142857142855,
            "best_regression": 0.0,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.42857142857142855,
                    "improvement": 0.42857142857142855,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 3,
                    "score": 0.3535714285714285,
                    "improvement": 0.42857142857142855,
                    "regression": 0.050000000000000044,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 10,
            "mean_accuracy": 0.86,
            "n_preserve_cases": 46,
            "n_hard_cases": 4,
            "train_accuracy": 0.92,
            "n_candidates": 2,
            "best_candidate_id": 1,
            "best_selection_score": 0.0,
            "best_improvement": 0.0,
            "best_regression": 0.0,
            "accepted": false,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 11,
            "mean_accuracy": 0.87,
            "n_preserve_cases": 46,
            "n_hard_cases": 4,
            "train_accuracy": 0.92,
            "n_candidates": 2,
            "best_candidate_id": 2,
            "best_selection_score": 0.25,
            "best_improvement": 0.25,
            "best_regression": 0.0,
            "accepted": true,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.10000000000000003,
                    "improvement": 0.25,
                    "regression": 0.09999999999999998,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.25,
                    "improvement": 0.25,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        },
        {
            "step": 12,
            "mean_accuracy": 0.87,
            "n_preserve_cases": 46,
            "n_hard_cases": 4,
            "train_accuracy": 0.92,
            "n_candidates": 2,
            "best_candidate_id": 1,
            "best_selection_score": 0.0,
            "best_improvement": 0.0,
            "best_regression": 0.0,
            "accepted": false,
            "old_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "final_prompt": "Task: Answer a yes/no question using only the provided facts. Reason silently; do not show any reasoning.\n\nOutput format (strict):\n- Output exactly one line: Answer: True or Answer: False\n- Capital A, colon, single space, capital T/F. No other text, no punctuation, no quotes/code blocks, no leading/trailing spaces, no extra lines. Include exactly one \u201cAnswer:\u201d.\n\nCore evidence rule:\n- Use only the provided facts and the whitelisted micro-glossary. Do not invent scenarios, numbers, bridges, roles,",
            "candidate_results": [
                {
                    "id": 1,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                },
                {
                    "id": 2,
                    "score": 0.0,
                    "improvement": 0.0,
                    "regression": 0.0,
                    "source": "optimized_from_batch_of_2"
                }
            ]
        }
    ]
}