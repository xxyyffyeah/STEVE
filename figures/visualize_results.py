#!/usr/bin/env python3
"""
TextGrad ä¼˜åŒ–ç»“æœå¯è§†åŒ–è„šæœ¬

åˆ†æå¹¶æ¯”è¾ƒTextualAdamä¸æ ‡å‡†TextualGradientDescentä¼˜åŒ–å™¨çš„æ€§èƒ½è¡¨ç°ã€‚
ä¸“æ³¨äºtest_accçš„å˜åŒ–è¶‹åŠ¿ï¼Œæä¾›è¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”åˆ†æã€‚

è¿è¡Œæ–¹å¼:
python figures/visualize_results.py
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import platform

sns.set_style("whitegrid")
sns.set_palette("husl")

def load_results():
    """åŠ è½½ä¸¤ä¸ªä¼˜åŒ–å™¨çš„ç»“æœæ•°æ®"""
    current_dir = Path(__file__).parent
    
    # æ–‡ä»¶è·¯å¾„
    adam_file = current_dir / "results_BBH_object_counting_gpt-3.5-turbo-0125_textual_adam.json"
    standard_file = current_dir / "results_BBH_object_counting_gpt-3.5-turbo.json"
    
    results = {}
    
    # åŠ è½½TextualAdamç»“æœ
    if adam_file.exists():
        with open(adam_file, 'r', encoding='utf-8') as f:
            results['adam'] = json.load(f)
            print(f"åŠ è½½TextualAdamç»“æœ: {len(results['adam']['test_acc'])}ä¸ªè®­ç»ƒæ­¥éª¤")
    else:
        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°Adamç»“æœæ–‡ä»¶ {adam_file}")
        results['adam'] = None
    
    # åŠ è½½æ ‡å‡†ä¼˜åŒ–å™¨ç»“æœ
    if standard_file.exists():
        with open(standard_file, 'r', encoding='utf-8') as f:
            results['standard'] = json.load(f)
            print(f"åŠ è½½æ ‡å‡†ä¼˜åŒ–å™¨ç»“æœ: {len(results['standard']['test_acc'])}ä¸ªè®­ç»ƒæ­¥éª¤")
    else:
        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ ‡å‡†ä¼˜åŒ–å™¨ç»“æœæ–‡ä»¶ {standard_file}")
        results['standard'] = None
    
    return results

def calculate_accuracy_stats(test_acc_data):
    """è®¡ç®—æ¯ä¸ªæ­¥éª¤çš„å‡†ç¡®ç‡"""
    step_accuracies = []
    
    for step_data in test_acc_data:
        if isinstance(step_data, list):
            acc = np.mean(step_data)  # 0/1åºåˆ—çš„å‡å€¼å°±æ˜¯å‡†ç¡®ç‡
        else:
            acc = step_data
        step_accuracies.append(acc)
    
    return np.array(step_accuracies)

def plot_accuracy_trends(results):
    """ç»˜åˆ¶å‡†ç¡®ç‡å˜åŒ–è¶‹åŠ¿å¯¹æ¯”å›¾"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    colors = {'adam': '#FF6B6B', 'standard': '#4ECDC4'}
    labels = {'adam': 'TextualAdam', 'standard': 'TextualGradientDescent'}
    
    # å­å›¾1: å‡†ç¡®ç‡è¶‹åŠ¿çº¿
    for optimizer_name, data in results.items():
        if data is None:
            continue
            
        accuracies = calculate_accuracy_stats(data['test_acc'])
        steps = range(len(accuracies))
        
        # ç»˜åˆ¶å‡†ç¡®ç‡è¶‹åŠ¿çº¿
        ax1.plot(steps, accuracies, 
                label=labels[optimizer_name], 
                color=colors[optimizer_name], 
                linewidth=2.5, 
                marker='o', 
                markersize=6)
    
    ax1.set_xlabel('Optimization Steps', fontsize=12)
    ax1.set_ylabel('Test Accuracy', fontsize=12)
    ax1.set_title('Test Accuracy Trends During Optimization', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=11)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(0, 1.05)
    
    # å­å›¾2: æ€§èƒ½æ”¹è¿›å¯¹æ¯”
    improvements = {}
    final_accs = {}
    
    for optimizer_name, data in results.items():
        if data is None:
            continue
            
        accuracies = calculate_accuracy_stats(data['test_acc'])
        initial_acc = accuracies[0]
        final_acc = accuracies[-1]
        max_acc = np.max(accuracies)
        
        improvements[optimizer_name] = {
            'initial': initial_acc,
            'final': final_acc,
            'max': max_acc,
            'improvement': final_acc - initial_acc,
            'max_improvement': max_acc - initial_acc
        }
        final_accs[optimizer_name] = final_acc
    
    # ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾
    optimizers = list(improvements.keys())
    if optimizers:
        x_pos = np.arange(len(optimizers))
        
        initial_vals = [improvements[opt]['initial'] for opt in optimizers]
        final_vals = [improvements[opt]['final'] for opt in optimizers]
        max_vals = [improvements[opt]['max'] for opt in optimizers]
        
        width = 0.25
        ax2.bar(x_pos - width, initial_vals, width, 
               label='Initial Accuracy', color='lightgray', alpha=0.7)
        ax2.bar(x_pos, final_vals, width, 
               label='Final Accuracy', color=[colors[opt] for opt in optimizers])
        ax2.bar(x_pos + width, max_vals, width, 
               label='Max Accuracy', color=[colors[opt] for opt in optimizers], alpha=0.6)
        ax2.set_xlabel('Optimizer Type', fontsize=12)
        ax2.set_ylabel('Accuracy', fontsize=12)
        ax2.set_title('Performance Comparison Overview', fontsize=14, fontweight='bold')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels([labels[opt] for opt in optimizers])
        ax2.legend(fontsize=10)
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim(0, 1.05)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (initial_val, final_val, max_val) in enumerate(zip(initial_vals, final_vals, max_vals)):
            # åˆå§‹å€¼æ ‡ç­¾
            ax2.text(i - width, initial_val + 0.02, f'{initial_val:.3f}', 
                    ha='center', va='bottom', fontweight='bold', fontsize=9)
            # æœ€ç»ˆå€¼æ ‡ç­¾
            ax2.text(i, final_val + 0.02, f'{final_val:.3f}', 
                    ha='center', va='bottom', fontweight='bold', fontsize=9)
            # æœ€é«˜å€¼æ ‡ç­¾
            ax2.text(i + width, max_val + 0.02, f'{max_val:.3f}', 
                    ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    plt.tight_layout()
    return fig, improvements

def print_detailed_analysis(results):
    """æ‰“å°è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“Š TextGrad ä¼˜åŒ–å™¨æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print("="*60)
    
    for optimizer_name, data in results.items():
        if data is None:
            continue
            
        optimizer_label = "TextualAdam" if optimizer_name == 'adam' else "TextualGradientDescent"
        print(f"\nğŸ” {optimizer_label} åˆ†æ:")
        print("-" * 40)
        
        accuracies = calculate_accuracy_stats(data['test_acc'])
        
        print(f"æ€»è®­ç»ƒæ­¥éª¤: {len(accuracies)}")
        print(f"åˆå§‹å‡†ç¡®ç‡: {accuracies[0]:.4f}")
        print(f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracies[-1]:.4f}")
        print(f"æœ€é«˜å‡†ç¡®ç‡: {np.max(accuracies):.4f}")
        print(f"æœ€ä½å‡†ç¡®ç‡: {np.min(accuracies):.4f}")
        print(f"å¹³å‡å‡†ç¡®ç‡: {np.mean(accuracies):.4f}")
        print(f"å‡†ç¡®ç‡æ ‡å‡†å·®: {np.std(accuracies):.4f}")
        print(f"æ€§èƒ½æ”¹è¿›: {accuracies[-1] - accuracies[0]:+.4f}")
        
        # åˆ†æä¼˜åŒ–å™¨ç‰¹å®šä¿¡æ¯
        if optimizer_name == 'adam' and 'optimizer_config' in data:
            config = data['optimizer_config']
            print(f"\nAdamå‚æ•°é…ç½®:")
            print(f"  Beta1: {config.get('beta1', 'N/A')}")
            print(f"  Beta2: {config.get('beta2', 'N/A')}")
            print(f"  Epsilon: {config.get('epsilon', 'N/A')}")
            print(f"  åŠ¨é‡çª—å£: {config.get('momentum_window', 'N/A')}")
        
        if 'performance_summary' in data:
            summary = data['performance_summary']
            print(f"\næ€§èƒ½æ‘˜è¦:")
            print(f"  æ”¹è¿›å¹…åº¦: {summary.get('improvement', 0):+.4f}")
            print(f"  ä¼˜åŒ–æ­¥æ•°: {summary.get('total_steps', len(accuracies)-1)}")

def compare_optimizers(results):
    """æ¯”è¾ƒä¸¤ä¸ªä¼˜åŒ–å™¨çš„æ€§èƒ½"""
    if results['adam'] is None or results['standard'] is None:
        print("\nâš ï¸  æ— æ³•è¿›è¡Œæ¯”è¾ƒ: ç¼ºå°‘æŸä¸ªä¼˜åŒ–å™¨çš„æ•°æ®")
        return
    
    print("\n" + "="*60)
    print("âš”ï¸  ä¼˜åŒ–å™¨æ€§èƒ½å¯¹æ¯”")
    print("="*60)
    
    adam_acc = calculate_accuracy_stats(results['adam']['test_acc'])
    standard_acc = calculate_accuracy_stats(results['standard']['test_acc'])
    
    adam_final = adam_acc[-1]
    standard_final = standard_acc[-1]
    
    print(f"\næœ€ç»ˆæ€§èƒ½å¯¹æ¯”:")
    print(f"TextualAdam:           {adam_final:.4f}")
    print(f"TextualGradientDescent: {standard_final:.4f}")
    print(f"æ€§èƒ½å·®å¼‚:              {adam_final - standard_final:+.4f}")
    
    # åˆ¤æ–­å“ªä¸ªæ›´å¥½
    if adam_final > standard_final:
        winner = "TextualAdam"
        margin = adam_final - standard_final
    elif standard_final > adam_final:
        winner = "TextualGradientDescent"
        margin = standard_final - adam_final
    else:
        winner = "å¹³å±€"
        margin = 0
    
    print(f"\nğŸ† ä¼˜èƒœè€…: {winner}")
    if margin > 0:
        print(f"é¢†å…ˆä¼˜åŠ¿: {margin:.4f} ({margin*100:.2f}%)")
    
    # æ”¶æ•›é€Ÿåº¦åˆ†æ
    adam_improvement = adam_acc[-1] - adam_acc[0]
    standard_improvement = standard_acc[-1] - standard_acc[0]
    
    print(f"\nğŸ“ˆ æ”¹è¿›å¹…åº¦å¯¹æ¯”:")
    print(f"TextualAdam:           {adam_improvement:+.4f}")
    print(f"TextualGradientDescent: {standard_improvement:+.4f}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†æTextGradä¼˜åŒ–ç»“æœ...")
    
    # åŠ è½½æ•°æ®
    results = load_results()
    
    if not any(results.values()):
        print("âŒ é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æœæ–‡ä»¶")
        return
    
    # æ‰“å°è¯¦ç»†åˆ†æ
    print_detailed_analysis(results)
    
    # æ¯”è¾ƒä¼˜åŒ–å™¨æ€§èƒ½
    compare_optimizers(results)
    
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    fig, _ = plot_accuracy_trends(results)
    
    # ä¿å­˜å›¾è¡¨
    output_path = Path(__file__).parent / "accuracy_comparison.png"
    fig.savefig(output_path, dpi=300, bbox_inches='tight', 
               facecolor='white', edgecolor='none')
    print(f"âœ… å›¾è¡¨å·²ä¿å­˜è‡³: {output_path}")
    
    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()